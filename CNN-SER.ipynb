{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from matplotlib.pyplot import specgram\n",
    "import keras\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.layers import Input, Flatten, Dropout, Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torchaudio\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Actor_01', 'Actor_02', 'Actor_03', 'Actor_04', 'Actor_05']"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RAV = \"../dataset/audio_speech_actors_01-24/\"\n",
    "dir_list = os.listdir(RAV)\n",
    "dir_list[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male_neutral       144\n",
       "female_neutral     144\n",
       "male_happy          96\n",
       "male_sad            96\n",
       "male_angry          96\n",
       "male_fear           96\n",
       "male_disgust        96\n",
       "male_surprise       96\n",
       "female_happy        96\n",
       "female_sad          96\n",
       "female_angry        96\n",
       "female_fear         96\n",
       "female_disgust      96\n",
       "female_surprise     96\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_list = os.listdir(RAV)\n",
    "dir_list.sort()\n",
    "\n",
    "emotion = []\n",
    "gender = []\n",
    "path = []\n",
    "for i in dir_list:\n",
    "    fname = os.listdir(RAV + i)\n",
    "    for f in fname:\n",
    "        part = f.split('.')[0].split('-')\n",
    "        emotion.append(int(part[2]))\n",
    "        temp = int(part[6])\n",
    "        if temp%2 == 0:\n",
    "            temp = \"female\"\n",
    "        else:\n",
    "            temp = \"male\"\n",
    "        gender.append(temp)\n",
    "        path.append(RAV + i + '/' + f)\n",
    "\n",
    "        \n",
    "RAV_df = pd.DataFrame(emotion)\n",
    "RAV_df = RAV_df.replace({1:'neutral', 2:'neutral', 3:'happy', 4:'sad', 5:'angry', 6:'fear', 7:'disgust', 8:'surprise'})\n",
    "RAV_df = pd.concat([pd.DataFrame(gender),RAV_df],axis=1)\n",
    "RAV_df.columns = ['gender','emotion']\n",
    "RAV_df['labels'] =RAV_df.gender + '_' + RAV_df.emotion\n",
    "RAV_df['source'] = 'RAVDESS'  \n",
    "RAV_df = pd.concat([RAV_df,pd.DataFrame(path, columns = ['path'])],axis=1)\n",
    "RAV_df = RAV_df.drop(['gender', 'emotion'], axis=1)\n",
    "RAV_df.labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>source</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male_neutral</td>\n",
       "      <td>RAVDESS</td>\n",
       "      <td>../dataset/audio_speech_actors_01-24/Actor_01/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>male_neutral</td>\n",
       "      <td>RAVDESS</td>\n",
       "      <td>../dataset/audio_speech_actors_01-24/Actor_01/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>male_neutral</td>\n",
       "      <td>RAVDESS</td>\n",
       "      <td>../dataset/audio_speech_actors_01-24/Actor_01/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male_neutral</td>\n",
       "      <td>RAVDESS</td>\n",
       "      <td>../dataset/audio_speech_actors_01-24/Actor_01/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male_neutral</td>\n",
       "      <td>RAVDESS</td>\n",
       "      <td>../dataset/audio_speech_actors_01-24/Actor_01/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>female_surprise</td>\n",
       "      <td>RAVDESS</td>\n",
       "      <td>../dataset/audio_speech_actors_01-24/Actor_24/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>female_surprise</td>\n",
       "      <td>RAVDESS</td>\n",
       "      <td>../dataset/audio_speech_actors_01-24/Actor_24/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>female_surprise</td>\n",
       "      <td>RAVDESS</td>\n",
       "      <td>../dataset/audio_speech_actors_01-24/Actor_24/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>female_surprise</td>\n",
       "      <td>RAVDESS</td>\n",
       "      <td>../dataset/audio_speech_actors_01-24/Actor_24/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>female_surprise</td>\n",
       "      <td>RAVDESS</td>\n",
       "      <td>../dataset/audio_speech_actors_01-24/Actor_24/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1440 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               labels   source  \\\n",
       "0        male_neutral  RAVDESS   \n",
       "1        male_neutral  RAVDESS   \n",
       "2        male_neutral  RAVDESS   \n",
       "3        male_neutral  RAVDESS   \n",
       "4        male_neutral  RAVDESS   \n",
       "...               ...      ...   \n",
       "1435  female_surprise  RAVDESS   \n",
       "1436  female_surprise  RAVDESS   \n",
       "1437  female_surprise  RAVDESS   \n",
       "1438  female_surprise  RAVDESS   \n",
       "1439  female_surprise  RAVDESS   \n",
       "\n",
       "                                                   path  \n",
       "0     ../dataset/audio_speech_actors_01-24/Actor_01/...  \n",
       "1     ../dataset/audio_speech_actors_01-24/Actor_01/...  \n",
       "2     ../dataset/audio_speech_actors_01-24/Actor_01/...  \n",
       "3     ../dataset/audio_speech_actors_01-24/Actor_01/...  \n",
       "4     ../dataset/audio_speech_actors_01-24/Actor_01/...  \n",
       "...                                                 ...  \n",
       "1435  ../dataset/audio_speech_actors_01-24/Actor_24/...  \n",
       "1436  ../dataset/audio_speech_actors_01-24/Actor_24/...  \n",
       "1437  ../dataset/audio_speech_actors_01-24/Actor_24/...  \n",
       "1438  ../dataset/audio_speech_actors_01-24/Actor_24/...  \n",
       "1439  ../dataset/audio_speech_actors_01-24/Actor_24/...  \n",
       "\n",
       "[1440 rows x 3 columns]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RAV_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels:  ['male_neutral' 'male_happy' 'male_sad' 'male_angry' 'male_fear'\n",
      " 'male_disgust' 'male_surprise' 'female_neutral' 'female_happy'\n",
      " 'female_sad' 'female_angry' 'female_fear' 'female_disgust'\n",
      " 'female_surprise']\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>female_angry</th>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female_disgust</th>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female_fear</th>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female_happy</th>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female_neutral</th>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female_sad</th>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female_surprise</th>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male_angry</th>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male_disgust</th>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male_fear</th>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male_happy</th>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male_neutral</th>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male_sad</th>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male_surprise</th>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 path\n",
       "labels               \n",
       "female_angry       96\n",
       "female_disgust     96\n",
       "female_fear        96\n",
       "female_happy       96\n",
       "female_neutral    144\n",
       "female_sad         96\n",
       "female_surprise    96\n",
       "male_angry         96\n",
       "male_disgust       96\n",
       "male_fear          96\n",
       "male_happy         96\n",
       "male_neutral      144\n",
       "male_sad           96\n",
       "male_surprise      96"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Labels: \", RAV_df[\"labels\"].unique())\n",
    "print()\n",
    "RAV_df.groupby(\"labels\").count()[[\"path\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1152, 3)\n",
      "(288, 3)\n"
     ]
    }
   ],
   "source": [
    "save_path = \"../content/data\"\n",
    "\n",
    "train_df, test_df = train_test_split(RAV_df, test_size=0.2, random_state=101, stratify=RAV_df[\"labels\"])\n",
    "\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "train_df.to_csv(f\"{save_path}/train.csv\", sep=\"\\t\", encoding=\"utf-8\", index=False)\n",
    "test_df.to_csv(f\"{save_path}/test.csv\", sep=\"\\t\", encoding=\"utf-8\", index=False)\n",
    "\n",
    "\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the audio file's waveform and its spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%` not found.\n"
     ]
    }
   ],
   "source": [
    "% pylab inline\n",
    "import os\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import glob \n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "librosa.display.waveplot(data, sr=sampling_rate)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import scipy.io.wavfile\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "\n",
    "sr,x = scipy.io.wavfile.read('RawData/f10 (2).wav')\n",
    "\n",
    "## Parameters: 10ms step, 30ms window\n",
    "nstep = int(sr * 0.01)\n",
    "nwin  = int(sr * 0.03)\n",
    "nfft = nwin\n",
    "\n",
    "window = np.hamming(nwin)\n",
    "\n",
    "## will take windows x[n1:n2].  generate\n",
    "## and loop over n2 such that all frames\n",
    "## fit within the waveform\n",
    "nn = range(nwin, len(x), nstep)\n",
    "\n",
    "X = np.zeros( (len(nn), nfft//2) )\n",
    "\n",
    "for i,n in enumerate(nn):\n",
    "    xseg = x[n-nwin:n]\n",
    "    z = np.fft.fft(window * xseg, nfft)\n",
    "    X[i,:] = np.log(np.abs(z[:nfft//2]))\n",
    "\n",
    "plt.imshow(X.T, interpolation='nearest',\n",
    "    origin='lower',\n",
    "    aspect='auto')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the labels"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "feeling_list=[]\n",
    "for item in mylist:\n",
    "    if item[6:-16]=='02' and int(item[18:-4])%2==0:\n",
    "        feeling_list.append('female_calm')\n",
    "    elif item[6:-16]=='02' and int(item[18:-4])%2==1:\n",
    "        feeling_list.append('male_calm')\n",
    "    elif item[6:-16]=='03' and int(item[18:-4])%2==0:\n",
    "        feeling_list.append('female_happy')\n",
    "    elif item[6:-16]=='03' and int(item[18:-4])%2==1:\n",
    "        feeling_list.append('male_happy')\n",
    "    elif item[6:-16]=='04' and int(item[18:-4])%2==0:\n",
    "        feeling_list.append('female_sad')\n",
    "    elif item[6:-16]=='04' and int(item[18:-4])%2==1:\n",
    "        feeling_list.append('male_sad')\n",
    "    elif item[6:-16]=='05' and int(item[18:-4])%2==0:\n",
    "        feeling_list.append('female_angry')\n",
    "    elif item[6:-16]=='05' and int(item[18:-4])%2==1:\n",
    "        feeling_list.append('male_angry')\n",
    "    elif item[6:-16]=='06' and int(item[18:-4])%2==0:\n",
    "        feeling_list.append('female_fearful')\n",
    "    elif item[6:-16]=='06' and int(item[18:-4])%2==1:\n",
    "        feeling_list.append('male_fearful')\n",
    "    elif item[:1]=='a':\n",
    "        feeling_list.append('male_angry')\n",
    "    elif item[:1]=='f':\n",
    "        feeling_list.append('male_fearful')\n",
    "    elif item[:1]=='h':\n",
    "        feeling_list.append('male_happy')\n",
    "    #elif item[:1]=='n':\n",
    "        #feeling_list.append('neutral')\n",
    "    elif item[:2]=='sa':\n",
    "        feeling_list.append('male_sad')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "labels = pd.DataFrame(feeling_list)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "labels[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the features of audio files using librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = RAV_df['path']\n",
    "df = pd.DataFrame(columns=['feature'])\n",
    "bookmark=0\n",
    "for index,y in enumerate(paths):\n",
    "    #print(index, y)\n",
    "    #if mylist[index][6:-16]!='01' and mylist[index][6:-16]!='07' and mylist[index][6:-16]!='08' and mylist[index][:2]!='su' and mylist[index][:1]!='n' and mylist[index][:1]!='d':\n",
    "    X, sample_rate = librosa.load(y, res_type='kaiser_fast',duration=2.5,sr=22050*2,offset=0.5)\n",
    "    sample_rate = np.array(sample_rate)\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=X, \n",
    "                                        sr=sample_rate, \n",
    "                                        n_mfcc=13),\n",
    "                    axis=0)\n",
    "    feature = mfccs\n",
    "    #[float(i) for i in feature]\n",
    "    #feature1=feature[:135]\n",
    "    df.loc[bookmark] = [feature]\n",
    "    bookmark=bookmark+1        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-65.80097, -65.80097, -65.80097, -65.80097, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-61.84994, -62.89504, -63.830635, -60.552586,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-65.81886, -65.81886, -65.81886, -65.81886, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-66.05848, -66.05848, -66.05848, -66.05848, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-70.26777, -70.26777, -70.26777, -70.26777, -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             feature\n",
       "0  [-65.80097, -65.80097, -65.80097, -65.80097, -...\n",
       "1  [-61.84994, -62.89504, -63.830635, -60.552586,...\n",
       "2  [-65.81886, -65.81886, -65.81886, -65.81886, -...\n",
       "3  [-66.05848, -66.05848, -66.05848, -66.05848, -...\n",
       "4  [-70.26777, -70.26777, -70.26777, -70.26777, -..."
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>206</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-65.800972</td>\n",
       "      <td>-65.800972</td>\n",
       "      <td>-65.800972</td>\n",
       "      <td>-65.800972</td>\n",
       "      <td>-65.800972</td>\n",
       "      <td>-65.800972</td>\n",
       "      <td>-65.800972</td>\n",
       "      <td>-65.800972</td>\n",
       "      <td>-65.800972</td>\n",
       "      <td>-65.800972</td>\n",
       "      <td>...</td>\n",
       "      <td>-58.299904</td>\n",
       "      <td>-62.295246</td>\n",
       "      <td>-64.930115</td>\n",
       "      <td>-65.332123</td>\n",
       "      <td>-64.116928</td>\n",
       "      <td>-64.319908</td>\n",
       "      <td>-64.971420</td>\n",
       "      <td>-63.155781</td>\n",
       "      <td>-64.178665</td>\n",
       "      <td>-63.061893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-61.849941</td>\n",
       "      <td>-62.895039</td>\n",
       "      <td>-63.830635</td>\n",
       "      <td>-60.552586</td>\n",
       "      <td>-60.821678</td>\n",
       "      <td>-62.073399</td>\n",
       "      <td>-64.889229</td>\n",
       "      <td>-65.389946</td>\n",
       "      <td>-65.389946</td>\n",
       "      <td>-65.389946</td>\n",
       "      <td>...</td>\n",
       "      <td>-65.389946</td>\n",
       "      <td>-65.389946</td>\n",
       "      <td>-65.389946</td>\n",
       "      <td>-65.389946</td>\n",
       "      <td>-65.389946</td>\n",
       "      <td>-65.389946</td>\n",
       "      <td>-65.389946</td>\n",
       "      <td>-65.389946</td>\n",
       "      <td>-65.389946</td>\n",
       "      <td>-65.389946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-65.818863</td>\n",
       "      <td>-65.818863</td>\n",
       "      <td>-65.818863</td>\n",
       "      <td>-65.818863</td>\n",
       "      <td>-65.805527</td>\n",
       "      <td>-65.818863</td>\n",
       "      <td>-65.818863</td>\n",
       "      <td>-65.629539</td>\n",
       "      <td>-64.802628</td>\n",
       "      <td>-65.818863</td>\n",
       "      <td>...</td>\n",
       "      <td>-65.818863</td>\n",
       "      <td>-65.818863</td>\n",
       "      <td>-65.818863</td>\n",
       "      <td>-65.818863</td>\n",
       "      <td>-65.438057</td>\n",
       "      <td>-65.684853</td>\n",
       "      <td>-65.818863</td>\n",
       "      <td>-65.818863</td>\n",
       "      <td>-65.818863</td>\n",
       "      <td>-65.818863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-66.058479</td>\n",
       "      <td>-66.058479</td>\n",
       "      <td>-66.058479</td>\n",
       "      <td>-66.058479</td>\n",
       "      <td>-66.058479</td>\n",
       "      <td>-66.058479</td>\n",
       "      <td>-66.058479</td>\n",
       "      <td>-66.058479</td>\n",
       "      <td>-66.058479</td>\n",
       "      <td>-66.058479</td>\n",
       "      <td>...</td>\n",
       "      <td>-57.539616</td>\n",
       "      <td>-55.826317</td>\n",
       "      <td>-57.741989</td>\n",
       "      <td>-59.796379</td>\n",
       "      <td>-60.975368</td>\n",
       "      <td>-62.663052</td>\n",
       "      <td>-64.573494</td>\n",
       "      <td>-63.782608</td>\n",
       "      <td>-61.515789</td>\n",
       "      <td>-58.214882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-70.267769</td>\n",
       "      <td>-70.267769</td>\n",
       "      <td>-70.267769</td>\n",
       "      <td>-70.267769</td>\n",
       "      <td>-70.267769</td>\n",
       "      <td>-70.267769</td>\n",
       "      <td>-70.267769</td>\n",
       "      <td>-70.267769</td>\n",
       "      <td>-70.267769</td>\n",
       "      <td>-70.267769</td>\n",
       "      <td>...</td>\n",
       "      <td>-58.802044</td>\n",
       "      <td>-57.447464</td>\n",
       "      <td>-58.896500</td>\n",
       "      <td>-58.750996</td>\n",
       "      <td>-57.405678</td>\n",
       "      <td>-60.078484</td>\n",
       "      <td>-63.426800</td>\n",
       "      <td>-62.638542</td>\n",
       "      <td>-61.082741</td>\n",
       "      <td>-60.234661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>-58.988811</td>\n",
       "      <td>-58.988811</td>\n",
       "      <td>-60.665466</td>\n",
       "      <td>-60.689583</td>\n",
       "      <td>-59.735569</td>\n",
       "      <td>-60.501480</td>\n",
       "      <td>-60.420517</td>\n",
       "      <td>-59.816250</td>\n",
       "      <td>-60.189262</td>\n",
       "      <td>-60.110905</td>\n",
       "      <td>...</td>\n",
       "      <td>-58.988811</td>\n",
       "      <td>-58.988811</td>\n",
       "      <td>-58.988811</td>\n",
       "      <td>-58.916401</td>\n",
       "      <td>-58.988811</td>\n",
       "      <td>-58.988811</td>\n",
       "      <td>-58.988811</td>\n",
       "      <td>-58.988811</td>\n",
       "      <td>-58.988811</td>\n",
       "      <td>-58.988811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>-54.677158</td>\n",
       "      <td>-54.677158</td>\n",
       "      <td>-54.677158</td>\n",
       "      <td>-54.677158</td>\n",
       "      <td>-54.677158</td>\n",
       "      <td>-54.677158</td>\n",
       "      <td>-54.677158</td>\n",
       "      <td>-54.677158</td>\n",
       "      <td>-54.677158</td>\n",
       "      <td>-54.677158</td>\n",
       "      <td>...</td>\n",
       "      <td>-38.598328</td>\n",
       "      <td>-38.009247</td>\n",
       "      <td>-40.035809</td>\n",
       "      <td>-39.657108</td>\n",
       "      <td>-40.550026</td>\n",
       "      <td>-43.559956</td>\n",
       "      <td>-45.444458</td>\n",
       "      <td>-46.496017</td>\n",
       "      <td>-46.470703</td>\n",
       "      <td>-47.322212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>-56.940815</td>\n",
       "      <td>-56.940815</td>\n",
       "      <td>-56.940815</td>\n",
       "      <td>-56.940815</td>\n",
       "      <td>-56.940815</td>\n",
       "      <td>-56.943363</td>\n",
       "      <td>-57.077030</td>\n",
       "      <td>-56.940815</td>\n",
       "      <td>-56.940815</td>\n",
       "      <td>-57.228634</td>\n",
       "      <td>...</td>\n",
       "      <td>-43.485592</td>\n",
       "      <td>-42.686459</td>\n",
       "      <td>-44.226131</td>\n",
       "      <td>-44.101894</td>\n",
       "      <td>-43.651344</td>\n",
       "      <td>-45.493496</td>\n",
       "      <td>-47.759686</td>\n",
       "      <td>-50.536503</td>\n",
       "      <td>-51.336391</td>\n",
       "      <td>-50.690861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>-55.255135</td>\n",
       "      <td>-55.255135</td>\n",
       "      <td>-55.186649</td>\n",
       "      <td>-55.345291</td>\n",
       "      <td>-55.053379</td>\n",
       "      <td>-53.088177</td>\n",
       "      <td>-52.199924</td>\n",
       "      <td>-52.218304</td>\n",
       "      <td>-52.633869</td>\n",
       "      <td>-51.629967</td>\n",
       "      <td>...</td>\n",
       "      <td>-47.927128</td>\n",
       "      <td>-50.145138</td>\n",
       "      <td>-48.712173</td>\n",
       "      <td>-47.603024</td>\n",
       "      <td>-45.205418</td>\n",
       "      <td>-44.438683</td>\n",
       "      <td>-48.720501</td>\n",
       "      <td>-50.850346</td>\n",
       "      <td>-50.327168</td>\n",
       "      <td>-48.915745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>-48.668430</td>\n",
       "      <td>-45.720394</td>\n",
       "      <td>-46.046833</td>\n",
       "      <td>-46.525803</td>\n",
       "      <td>-47.946480</td>\n",
       "      <td>-44.790188</td>\n",
       "      <td>-43.489738</td>\n",
       "      <td>-46.490620</td>\n",
       "      <td>-50.799656</td>\n",
       "      <td>-50.240376</td>\n",
       "      <td>...</td>\n",
       "      <td>-43.185242</td>\n",
       "      <td>-45.281612</td>\n",
       "      <td>-48.504025</td>\n",
       "      <td>-50.357990</td>\n",
       "      <td>-44.687363</td>\n",
       "      <td>-43.194416</td>\n",
       "      <td>-46.666641</td>\n",
       "      <td>-50.128151</td>\n",
       "      <td>-50.941978</td>\n",
       "      <td>-50.317818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1440 rows Ã— 216 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0          1          2          3          4          5    \\\n",
       "0    -65.800972 -65.800972 -65.800972 -65.800972 -65.800972 -65.800972   \n",
       "1    -61.849941 -62.895039 -63.830635 -60.552586 -60.821678 -62.073399   \n",
       "2    -65.818863 -65.818863 -65.818863 -65.818863 -65.805527 -65.818863   \n",
       "3    -66.058479 -66.058479 -66.058479 -66.058479 -66.058479 -66.058479   \n",
       "4    -70.267769 -70.267769 -70.267769 -70.267769 -70.267769 -70.267769   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "1435 -58.988811 -58.988811 -60.665466 -60.689583 -59.735569 -60.501480   \n",
       "1436 -54.677158 -54.677158 -54.677158 -54.677158 -54.677158 -54.677158   \n",
       "1437 -56.940815 -56.940815 -56.940815 -56.940815 -56.940815 -56.943363   \n",
       "1438 -55.255135 -55.255135 -55.186649 -55.345291 -55.053379 -53.088177   \n",
       "1439 -48.668430 -45.720394 -46.046833 -46.525803 -47.946480 -44.790188   \n",
       "\n",
       "            6          7          8          9    ...        206        207  \\\n",
       "0    -65.800972 -65.800972 -65.800972 -65.800972  ... -58.299904 -62.295246   \n",
       "1    -64.889229 -65.389946 -65.389946 -65.389946  ... -65.389946 -65.389946   \n",
       "2    -65.818863 -65.629539 -64.802628 -65.818863  ... -65.818863 -65.818863   \n",
       "3    -66.058479 -66.058479 -66.058479 -66.058479  ... -57.539616 -55.826317   \n",
       "4    -70.267769 -70.267769 -70.267769 -70.267769  ... -58.802044 -57.447464   \n",
       "...         ...        ...        ...        ...  ...        ...        ...   \n",
       "1435 -60.420517 -59.816250 -60.189262 -60.110905  ... -58.988811 -58.988811   \n",
       "1436 -54.677158 -54.677158 -54.677158 -54.677158  ... -38.598328 -38.009247   \n",
       "1437 -57.077030 -56.940815 -56.940815 -57.228634  ... -43.485592 -42.686459   \n",
       "1438 -52.199924 -52.218304 -52.633869 -51.629967  ... -47.927128 -50.145138   \n",
       "1439 -43.489738 -46.490620 -50.799656 -50.240376  ... -43.185242 -45.281612   \n",
       "\n",
       "            208        209        210        211        212        213  \\\n",
       "0    -64.930115 -65.332123 -64.116928 -64.319908 -64.971420 -63.155781   \n",
       "1    -65.389946 -65.389946 -65.389946 -65.389946 -65.389946 -65.389946   \n",
       "2    -65.818863 -65.818863 -65.438057 -65.684853 -65.818863 -65.818863   \n",
       "3    -57.741989 -59.796379 -60.975368 -62.663052 -64.573494 -63.782608   \n",
       "4    -58.896500 -58.750996 -57.405678 -60.078484 -63.426800 -62.638542   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "1435 -58.988811 -58.916401 -58.988811 -58.988811 -58.988811 -58.988811   \n",
       "1436 -40.035809 -39.657108 -40.550026 -43.559956 -45.444458 -46.496017   \n",
       "1437 -44.226131 -44.101894 -43.651344 -45.493496 -47.759686 -50.536503   \n",
       "1438 -48.712173 -47.603024 -45.205418 -44.438683 -48.720501 -50.850346   \n",
       "1439 -48.504025 -50.357990 -44.687363 -43.194416 -46.666641 -50.128151   \n",
       "\n",
       "            214        215  \n",
       "0    -64.178665 -63.061893  \n",
       "1    -65.389946 -65.389946  \n",
       "2    -65.818863 -65.818863  \n",
       "3    -61.515789 -58.214882  \n",
       "4    -61.082741 -60.234661  \n",
       "...         ...        ...  \n",
       "1435 -58.988811 -58.988811  \n",
       "1436 -46.470703 -47.322212  \n",
       "1437 -51.336391 -50.690861  \n",
       "1438 -50.327168 -48.915745  \n",
       "1439 -50.941978 -50.317818  \n",
       "\n",
       "[1440 rows x 216 columns]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = pd.DataFrame(df['feature'].values.tolist())\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df3[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = RAV_df['labels']\n",
    "newdf = pd.concat([df3,labels], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnewdf = newdf.rename(index=str, columns={\"0\": \"label\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-65.800972</td>\n",
       "      <td>-65.800972</td>\n",
       "      <td>-65.800972</td>\n",
       "      <td>-65.800972</td>\n",
       "      <td>-65.800972</td>\n",
       "      <td>-65.800972</td>\n",
       "      <td>-65.800972</td>\n",
       "      <td>-65.800972</td>\n",
       "      <td>-65.800972</td>\n",
       "      <td>-65.800972</td>\n",
       "      <td>...</td>\n",
       "      <td>-62.295246</td>\n",
       "      <td>-64.930115</td>\n",
       "      <td>-65.332123</td>\n",
       "      <td>-64.116928</td>\n",
       "      <td>-64.319908</td>\n",
       "      <td>-64.971420</td>\n",
       "      <td>-63.155781</td>\n",
       "      <td>-64.178665</td>\n",
       "      <td>-63.061893</td>\n",
       "      <td>male_neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-61.849941</td>\n",
       "      <td>-62.895039</td>\n",
       "      <td>-63.830635</td>\n",
       "      <td>-60.552586</td>\n",
       "      <td>-60.821678</td>\n",
       "      <td>-62.073399</td>\n",
       "      <td>-64.889229</td>\n",
       "      <td>-65.389946</td>\n",
       "      <td>-65.389946</td>\n",
       "      <td>-65.389946</td>\n",
       "      <td>...</td>\n",
       "      <td>-65.389946</td>\n",
       "      <td>-65.389946</td>\n",
       "      <td>-65.389946</td>\n",
       "      <td>-65.389946</td>\n",
       "      <td>-65.389946</td>\n",
       "      <td>-65.389946</td>\n",
       "      <td>-65.389946</td>\n",
       "      <td>-65.389946</td>\n",
       "      <td>-65.389946</td>\n",
       "      <td>male_neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-65.818863</td>\n",
       "      <td>-65.818863</td>\n",
       "      <td>-65.818863</td>\n",
       "      <td>-65.818863</td>\n",
       "      <td>-65.805527</td>\n",
       "      <td>-65.818863</td>\n",
       "      <td>-65.818863</td>\n",
       "      <td>-65.629539</td>\n",
       "      <td>-64.802628</td>\n",
       "      <td>-65.818863</td>\n",
       "      <td>...</td>\n",
       "      <td>-65.818863</td>\n",
       "      <td>-65.818863</td>\n",
       "      <td>-65.818863</td>\n",
       "      <td>-65.438057</td>\n",
       "      <td>-65.684853</td>\n",
       "      <td>-65.818863</td>\n",
       "      <td>-65.818863</td>\n",
       "      <td>-65.818863</td>\n",
       "      <td>-65.818863</td>\n",
       "      <td>male_neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-66.058479</td>\n",
       "      <td>-66.058479</td>\n",
       "      <td>-66.058479</td>\n",
       "      <td>-66.058479</td>\n",
       "      <td>-66.058479</td>\n",
       "      <td>-66.058479</td>\n",
       "      <td>-66.058479</td>\n",
       "      <td>-66.058479</td>\n",
       "      <td>-66.058479</td>\n",
       "      <td>-66.058479</td>\n",
       "      <td>...</td>\n",
       "      <td>-55.826317</td>\n",
       "      <td>-57.741989</td>\n",
       "      <td>-59.796379</td>\n",
       "      <td>-60.975368</td>\n",
       "      <td>-62.663052</td>\n",
       "      <td>-64.573494</td>\n",
       "      <td>-63.782608</td>\n",
       "      <td>-61.515789</td>\n",
       "      <td>-58.214882</td>\n",
       "      <td>male_neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-70.267769</td>\n",
       "      <td>-70.267769</td>\n",
       "      <td>-70.267769</td>\n",
       "      <td>-70.267769</td>\n",
       "      <td>-70.267769</td>\n",
       "      <td>-70.267769</td>\n",
       "      <td>-70.267769</td>\n",
       "      <td>-70.267769</td>\n",
       "      <td>-70.267769</td>\n",
       "      <td>-70.267769</td>\n",
       "      <td>...</td>\n",
       "      <td>-57.447464</td>\n",
       "      <td>-58.896500</td>\n",
       "      <td>-58.750996</td>\n",
       "      <td>-57.405678</td>\n",
       "      <td>-60.078484</td>\n",
       "      <td>-63.426800</td>\n",
       "      <td>-62.638542</td>\n",
       "      <td>-61.082741</td>\n",
       "      <td>-60.234661</td>\n",
       "      <td>male_neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-67.557388</td>\n",
       "      <td>-67.557388</td>\n",
       "      <td>-67.557388</td>\n",
       "      <td>-67.557388</td>\n",
       "      <td>-67.557388</td>\n",
       "      <td>-67.557388</td>\n",
       "      <td>-65.239815</td>\n",
       "      <td>-65.536194</td>\n",
       "      <td>-67.557388</td>\n",
       "      <td>-67.557388</td>\n",
       "      <td>...</td>\n",
       "      <td>-57.270752</td>\n",
       "      <td>-56.743652</td>\n",
       "      <td>-56.140930</td>\n",
       "      <td>-57.532017</td>\n",
       "      <td>-59.493046</td>\n",
       "      <td>-67.149849</td>\n",
       "      <td>-67.498711</td>\n",
       "      <td>-66.086418</td>\n",
       "      <td>-66.205048</td>\n",
       "      <td>male_neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-69.673286</td>\n",
       "      <td>-69.693306</td>\n",
       "      <td>-69.693306</td>\n",
       "      <td>-69.693306</td>\n",
       "      <td>-69.693306</td>\n",
       "      <td>-69.693306</td>\n",
       "      <td>-69.693306</td>\n",
       "      <td>-69.620773</td>\n",
       "      <td>-69.693306</td>\n",
       "      <td>-68.906570</td>\n",
       "      <td>...</td>\n",
       "      <td>-61.018559</td>\n",
       "      <td>-60.341145</td>\n",
       "      <td>-63.465332</td>\n",
       "      <td>-64.500137</td>\n",
       "      <td>-61.646843</td>\n",
       "      <td>-58.001488</td>\n",
       "      <td>-58.848484</td>\n",
       "      <td>-62.603935</td>\n",
       "      <td>-61.121773</td>\n",
       "      <td>male_neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-69.051399</td>\n",
       "      <td>-69.051399</td>\n",
       "      <td>-69.051399</td>\n",
       "      <td>-69.051399</td>\n",
       "      <td>-69.051399</td>\n",
       "      <td>-68.754860</td>\n",
       "      <td>-69.051399</td>\n",
       "      <td>-69.051399</td>\n",
       "      <td>-69.051399</td>\n",
       "      <td>-68.359085</td>\n",
       "      <td>...</td>\n",
       "      <td>-57.681641</td>\n",
       "      <td>-56.301266</td>\n",
       "      <td>-58.650131</td>\n",
       "      <td>-63.881088</td>\n",
       "      <td>-63.749409</td>\n",
       "      <td>-65.222473</td>\n",
       "      <td>-65.308250</td>\n",
       "      <td>-67.008553</td>\n",
       "      <td>-68.636299</td>\n",
       "      <td>male_neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-73.841370</td>\n",
       "      <td>-73.841370</td>\n",
       "      <td>-73.841370</td>\n",
       "      <td>-73.719650</td>\n",
       "      <td>-73.841370</td>\n",
       "      <td>-73.841370</td>\n",
       "      <td>-73.841370</td>\n",
       "      <td>-73.303635</td>\n",
       "      <td>-72.806808</td>\n",
       "      <td>-73.841370</td>\n",
       "      <td>...</td>\n",
       "      <td>-50.568867</td>\n",
       "      <td>-53.505844</td>\n",
       "      <td>-54.222256</td>\n",
       "      <td>-51.545525</td>\n",
       "      <td>-52.573784</td>\n",
       "      <td>-54.786297</td>\n",
       "      <td>-56.344280</td>\n",
       "      <td>-57.508217</td>\n",
       "      <td>-56.577332</td>\n",
       "      <td>male_neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-69.243256</td>\n",
       "      <td>-69.243256</td>\n",
       "      <td>-69.243256</td>\n",
       "      <td>-69.243256</td>\n",
       "      <td>-68.901970</td>\n",
       "      <td>-67.983002</td>\n",
       "      <td>-68.089203</td>\n",
       "      <td>-67.897331</td>\n",
       "      <td>-65.258011</td>\n",
       "      <td>-67.170975</td>\n",
       "      <td>...</td>\n",
       "      <td>-29.354748</td>\n",
       "      <td>-30.388712</td>\n",
       "      <td>-30.094086</td>\n",
       "      <td>-30.615465</td>\n",
       "      <td>-31.126341</td>\n",
       "      <td>-31.148714</td>\n",
       "      <td>-31.413185</td>\n",
       "      <td>-31.356203</td>\n",
       "      <td>-30.060383</td>\n",
       "      <td>male_neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-73.254967</td>\n",
       "      <td>-73.254967</td>\n",
       "      <td>-73.254967</td>\n",
       "      <td>-73.254967</td>\n",
       "      <td>-68.774429</td>\n",
       "      <td>-69.380402</td>\n",
       "      <td>-73.254967</td>\n",
       "      <td>-73.254967</td>\n",
       "      <td>-73.254967</td>\n",
       "      <td>-73.254967</td>\n",
       "      <td>...</td>\n",
       "      <td>-26.499784</td>\n",
       "      <td>-27.143425</td>\n",
       "      <td>-28.207592</td>\n",
       "      <td>-27.193054</td>\n",
       "      <td>-27.315336</td>\n",
       "      <td>-27.431173</td>\n",
       "      <td>-26.716452</td>\n",
       "      <td>-24.115793</td>\n",
       "      <td>-21.873396</td>\n",
       "      <td>male_neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-70.746513</td>\n",
       "      <td>-70.746513</td>\n",
       "      <td>-70.025284</td>\n",
       "      <td>-69.131271</td>\n",
       "      <td>-70.746513</td>\n",
       "      <td>-70.746513</td>\n",
       "      <td>-70.746513</td>\n",
       "      <td>-70.746513</td>\n",
       "      <td>-70.746513</td>\n",
       "      <td>-70.746513</td>\n",
       "      <td>...</td>\n",
       "      <td>-32.430035</td>\n",
       "      <td>-32.474728</td>\n",
       "      <td>-34.334457</td>\n",
       "      <td>-38.280952</td>\n",
       "      <td>-39.110352</td>\n",
       "      <td>-41.010277</td>\n",
       "      <td>-40.282722</td>\n",
       "      <td>-41.454048</td>\n",
       "      <td>-44.383205</td>\n",
       "      <td>male_neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-63.311062</td>\n",
       "      <td>-63.072487</td>\n",
       "      <td>-63.412422</td>\n",
       "      <td>-63.796757</td>\n",
       "      <td>-63.581989</td>\n",
       "      <td>-58.921223</td>\n",
       "      <td>-57.955044</td>\n",
       "      <td>-61.224972</td>\n",
       "      <td>-63.782932</td>\n",
       "      <td>-63.796757</td>\n",
       "      <td>...</td>\n",
       "      <td>-62.505020</td>\n",
       "      <td>-59.518867</td>\n",
       "      <td>-60.482346</td>\n",
       "      <td>-58.338570</td>\n",
       "      <td>-58.965298</td>\n",
       "      <td>-63.520664</td>\n",
       "      <td>-63.769352</td>\n",
       "      <td>-63.829861</td>\n",
       "      <td>-62.814236</td>\n",
       "      <td>male_happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-60.369045</td>\n",
       "      <td>-60.083717</td>\n",
       "      <td>-60.978924</td>\n",
       "      <td>-60.952457</td>\n",
       "      <td>-60.982483</td>\n",
       "      <td>-60.983948</td>\n",
       "      <td>-60.981255</td>\n",
       "      <td>-60.981255</td>\n",
       "      <td>-60.981255</td>\n",
       "      <td>-60.249615</td>\n",
       "      <td>...</td>\n",
       "      <td>-49.848366</td>\n",
       "      <td>-49.632915</td>\n",
       "      <td>-55.102585</td>\n",
       "      <td>-55.481716</td>\n",
       "      <td>-52.952229</td>\n",
       "      <td>-51.401585</td>\n",
       "      <td>-54.072971</td>\n",
       "      <td>-52.639565</td>\n",
       "      <td>-52.664181</td>\n",
       "      <td>male_happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-65.427315</td>\n",
       "      <td>-65.427315</td>\n",
       "      <td>-65.261780</td>\n",
       "      <td>-65.427315</td>\n",
       "      <td>-65.427315</td>\n",
       "      <td>-65.427315</td>\n",
       "      <td>-65.027588</td>\n",
       "      <td>-65.404327</td>\n",
       "      <td>-65.427315</td>\n",
       "      <td>-58.999031</td>\n",
       "      <td>...</td>\n",
       "      <td>-60.775375</td>\n",
       "      <td>-64.036736</td>\n",
       "      <td>-64.463486</td>\n",
       "      <td>-65.204987</td>\n",
       "      <td>-64.805725</td>\n",
       "      <td>-64.463928</td>\n",
       "      <td>-61.400517</td>\n",
       "      <td>-60.954338</td>\n",
       "      <td>-62.738239</td>\n",
       "      <td>male_happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-65.243347</td>\n",
       "      <td>-65.243347</td>\n",
       "      <td>-65.243347</td>\n",
       "      <td>-65.243347</td>\n",
       "      <td>-65.243347</td>\n",
       "      <td>-65.243347</td>\n",
       "      <td>-65.243347</td>\n",
       "      <td>-65.243347</td>\n",
       "      <td>-65.243347</td>\n",
       "      <td>-65.117577</td>\n",
       "      <td>...</td>\n",
       "      <td>-61.924271</td>\n",
       "      <td>-56.156918</td>\n",
       "      <td>-55.677975</td>\n",
       "      <td>-61.117817</td>\n",
       "      <td>-58.568733</td>\n",
       "      <td>-57.136806</td>\n",
       "      <td>-58.619907</td>\n",
       "      <td>-60.068314</td>\n",
       "      <td>-57.350605</td>\n",
       "      <td>male_happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-58.731003</td>\n",
       "      <td>-58.746517</td>\n",
       "      <td>-58.048584</td>\n",
       "      <td>-57.370796</td>\n",
       "      <td>-58.199924</td>\n",
       "      <td>-59.706638</td>\n",
       "      <td>-59.876179</td>\n",
       "      <td>-59.998066</td>\n",
       "      <td>-59.936649</td>\n",
       "      <td>-60.248569</td>\n",
       "      <td>...</td>\n",
       "      <td>-50.477974</td>\n",
       "      <td>-50.955284</td>\n",
       "      <td>-55.110638</td>\n",
       "      <td>-53.636642</td>\n",
       "      <td>-57.134220</td>\n",
       "      <td>-58.249916</td>\n",
       "      <td>-56.417946</td>\n",
       "      <td>-54.576748</td>\n",
       "      <td>-51.933964</td>\n",
       "      <td>male_happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-56.733879</td>\n",
       "      <td>-56.752663</td>\n",
       "      <td>-56.415257</td>\n",
       "      <td>-55.715679</td>\n",
       "      <td>-55.817852</td>\n",
       "      <td>-55.832748</td>\n",
       "      <td>-55.889751</td>\n",
       "      <td>-55.116520</td>\n",
       "      <td>-54.244675</td>\n",
       "      <td>-56.211891</td>\n",
       "      <td>...</td>\n",
       "      <td>-39.931885</td>\n",
       "      <td>-43.064491</td>\n",
       "      <td>-46.631512</td>\n",
       "      <td>-48.998482</td>\n",
       "      <td>-46.067894</td>\n",
       "      <td>-45.294285</td>\n",
       "      <td>-47.657375</td>\n",
       "      <td>-51.417202</td>\n",
       "      <td>-54.335350</td>\n",
       "      <td>male_happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-54.181858</td>\n",
       "      <td>-53.653313</td>\n",
       "      <td>-52.179523</td>\n",
       "      <td>-52.163277</td>\n",
       "      <td>-53.387512</td>\n",
       "      <td>-53.853840</td>\n",
       "      <td>-52.760700</td>\n",
       "      <td>-51.047825</td>\n",
       "      <td>-50.953312</td>\n",
       "      <td>-50.094379</td>\n",
       "      <td>...</td>\n",
       "      <td>-31.906055</td>\n",
       "      <td>-32.806931</td>\n",
       "      <td>-33.447651</td>\n",
       "      <td>-34.668095</td>\n",
       "      <td>-34.520309</td>\n",
       "      <td>-37.190556</td>\n",
       "      <td>-40.918858</td>\n",
       "      <td>-41.119217</td>\n",
       "      <td>-38.409359</td>\n",
       "      <td>male_happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-57.414993</td>\n",
       "      <td>-57.414993</td>\n",
       "      <td>-57.414993</td>\n",
       "      <td>-57.414993</td>\n",
       "      <td>-57.414993</td>\n",
       "      <td>-57.414993</td>\n",
       "      <td>-57.414993</td>\n",
       "      <td>-57.414993</td>\n",
       "      <td>-57.414993</td>\n",
       "      <td>-57.414993</td>\n",
       "      <td>...</td>\n",
       "      <td>-27.892962</td>\n",
       "      <td>-29.425556</td>\n",
       "      <td>-31.255730</td>\n",
       "      <td>-34.011837</td>\n",
       "      <td>-34.322582</td>\n",
       "      <td>-33.564938</td>\n",
       "      <td>-36.074425</td>\n",
       "      <td>-37.658699</td>\n",
       "      <td>-38.918003</td>\n",
       "      <td>male_happy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows Ã— 217 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0          1          2          3          4          5  \\\n",
       "0  -65.800972 -65.800972 -65.800972 -65.800972 -65.800972 -65.800972   \n",
       "1  -61.849941 -62.895039 -63.830635 -60.552586 -60.821678 -62.073399   \n",
       "2  -65.818863 -65.818863 -65.818863 -65.818863 -65.805527 -65.818863   \n",
       "3  -66.058479 -66.058479 -66.058479 -66.058479 -66.058479 -66.058479   \n",
       "4  -70.267769 -70.267769 -70.267769 -70.267769 -70.267769 -70.267769   \n",
       "5  -67.557388 -67.557388 -67.557388 -67.557388 -67.557388 -67.557388   \n",
       "6  -69.673286 -69.693306 -69.693306 -69.693306 -69.693306 -69.693306   \n",
       "7  -69.051399 -69.051399 -69.051399 -69.051399 -69.051399 -68.754860   \n",
       "8  -73.841370 -73.841370 -73.841370 -73.719650 -73.841370 -73.841370   \n",
       "9  -69.243256 -69.243256 -69.243256 -69.243256 -68.901970 -67.983002   \n",
       "10 -73.254967 -73.254967 -73.254967 -73.254967 -68.774429 -69.380402   \n",
       "11 -70.746513 -70.746513 -70.025284 -69.131271 -70.746513 -70.746513   \n",
       "12 -63.311062 -63.072487 -63.412422 -63.796757 -63.581989 -58.921223   \n",
       "13 -60.369045 -60.083717 -60.978924 -60.952457 -60.982483 -60.983948   \n",
       "14 -65.427315 -65.427315 -65.261780 -65.427315 -65.427315 -65.427315   \n",
       "15 -65.243347 -65.243347 -65.243347 -65.243347 -65.243347 -65.243347   \n",
       "16 -58.731003 -58.746517 -58.048584 -57.370796 -58.199924 -59.706638   \n",
       "17 -56.733879 -56.752663 -56.415257 -55.715679 -55.817852 -55.832748   \n",
       "18 -54.181858 -53.653313 -52.179523 -52.163277 -53.387512 -53.853840   \n",
       "19 -57.414993 -57.414993 -57.414993 -57.414993 -57.414993 -57.414993   \n",
       "\n",
       "            6          7          8          9  ...        207        208  \\\n",
       "0  -65.800972 -65.800972 -65.800972 -65.800972  ... -62.295246 -64.930115   \n",
       "1  -64.889229 -65.389946 -65.389946 -65.389946  ... -65.389946 -65.389946   \n",
       "2  -65.818863 -65.629539 -64.802628 -65.818863  ... -65.818863 -65.818863   \n",
       "3  -66.058479 -66.058479 -66.058479 -66.058479  ... -55.826317 -57.741989   \n",
       "4  -70.267769 -70.267769 -70.267769 -70.267769  ... -57.447464 -58.896500   \n",
       "5  -65.239815 -65.536194 -67.557388 -67.557388  ... -57.270752 -56.743652   \n",
       "6  -69.693306 -69.620773 -69.693306 -68.906570  ... -61.018559 -60.341145   \n",
       "7  -69.051399 -69.051399 -69.051399 -68.359085  ... -57.681641 -56.301266   \n",
       "8  -73.841370 -73.303635 -72.806808 -73.841370  ... -50.568867 -53.505844   \n",
       "9  -68.089203 -67.897331 -65.258011 -67.170975  ... -29.354748 -30.388712   \n",
       "10 -73.254967 -73.254967 -73.254967 -73.254967  ... -26.499784 -27.143425   \n",
       "11 -70.746513 -70.746513 -70.746513 -70.746513  ... -32.430035 -32.474728   \n",
       "12 -57.955044 -61.224972 -63.782932 -63.796757  ... -62.505020 -59.518867   \n",
       "13 -60.981255 -60.981255 -60.981255 -60.249615  ... -49.848366 -49.632915   \n",
       "14 -65.027588 -65.404327 -65.427315 -58.999031  ... -60.775375 -64.036736   \n",
       "15 -65.243347 -65.243347 -65.243347 -65.117577  ... -61.924271 -56.156918   \n",
       "16 -59.876179 -59.998066 -59.936649 -60.248569  ... -50.477974 -50.955284   \n",
       "17 -55.889751 -55.116520 -54.244675 -56.211891  ... -39.931885 -43.064491   \n",
       "18 -52.760700 -51.047825 -50.953312 -50.094379  ... -31.906055 -32.806931   \n",
       "19 -57.414993 -57.414993 -57.414993 -57.414993  ... -27.892962 -29.425556   \n",
       "\n",
       "          209        210        211        212        213        214  \\\n",
       "0  -65.332123 -64.116928 -64.319908 -64.971420 -63.155781 -64.178665   \n",
       "1  -65.389946 -65.389946 -65.389946 -65.389946 -65.389946 -65.389946   \n",
       "2  -65.818863 -65.438057 -65.684853 -65.818863 -65.818863 -65.818863   \n",
       "3  -59.796379 -60.975368 -62.663052 -64.573494 -63.782608 -61.515789   \n",
       "4  -58.750996 -57.405678 -60.078484 -63.426800 -62.638542 -61.082741   \n",
       "5  -56.140930 -57.532017 -59.493046 -67.149849 -67.498711 -66.086418   \n",
       "6  -63.465332 -64.500137 -61.646843 -58.001488 -58.848484 -62.603935   \n",
       "7  -58.650131 -63.881088 -63.749409 -65.222473 -65.308250 -67.008553   \n",
       "8  -54.222256 -51.545525 -52.573784 -54.786297 -56.344280 -57.508217   \n",
       "9  -30.094086 -30.615465 -31.126341 -31.148714 -31.413185 -31.356203   \n",
       "10 -28.207592 -27.193054 -27.315336 -27.431173 -26.716452 -24.115793   \n",
       "11 -34.334457 -38.280952 -39.110352 -41.010277 -40.282722 -41.454048   \n",
       "12 -60.482346 -58.338570 -58.965298 -63.520664 -63.769352 -63.829861   \n",
       "13 -55.102585 -55.481716 -52.952229 -51.401585 -54.072971 -52.639565   \n",
       "14 -64.463486 -65.204987 -64.805725 -64.463928 -61.400517 -60.954338   \n",
       "15 -55.677975 -61.117817 -58.568733 -57.136806 -58.619907 -60.068314   \n",
       "16 -55.110638 -53.636642 -57.134220 -58.249916 -56.417946 -54.576748   \n",
       "17 -46.631512 -48.998482 -46.067894 -45.294285 -47.657375 -51.417202   \n",
       "18 -33.447651 -34.668095 -34.520309 -37.190556 -40.918858 -41.119217   \n",
       "19 -31.255730 -34.011837 -34.322582 -33.564938 -36.074425 -37.658699   \n",
       "\n",
       "          215        labels  \n",
       "0  -63.061893  male_neutral  \n",
       "1  -65.389946  male_neutral  \n",
       "2  -65.818863  male_neutral  \n",
       "3  -58.214882  male_neutral  \n",
       "4  -60.234661  male_neutral  \n",
       "5  -66.205048  male_neutral  \n",
       "6  -61.121773  male_neutral  \n",
       "7  -68.636299  male_neutral  \n",
       "8  -56.577332  male_neutral  \n",
       "9  -30.060383  male_neutral  \n",
       "10 -21.873396  male_neutral  \n",
       "11 -44.383205  male_neutral  \n",
       "12 -62.814236    male_happy  \n",
       "13 -52.664181    male_happy  \n",
       "14 -62.738239    male_happy  \n",
       "15 -57.350605    male_happy  \n",
       "16 -51.933964    male_happy  \n",
       "17 -54.335350    male_happy  \n",
       "18 -38.409359    male_happy  \n",
       "19 -38.918003    male_happy  \n",
       "\n",
       "[20 rows x 217 columns]"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnewdf[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>-68.854813</td>\n",
       "      <td>-68.854813</td>\n",
       "      <td>-68.854813</td>\n",
       "      <td>-68.854813</td>\n",
       "      <td>-68.854813</td>\n",
       "      <td>-68.854813</td>\n",
       "      <td>-68.854813</td>\n",
       "      <td>-68.854813</td>\n",
       "      <td>-68.854813</td>\n",
       "      <td>-68.854813</td>\n",
       "      <td>...</td>\n",
       "      <td>-68.792786</td>\n",
       "      <td>-68.723152</td>\n",
       "      <td>-68.000206</td>\n",
       "      <td>-66.457191</td>\n",
       "      <td>-68.129662</td>\n",
       "      <td>-68.811119</td>\n",
       "      <td>-67.433525</td>\n",
       "      <td>-67.296227</td>\n",
       "      <td>-68.486076</td>\n",
       "      <td>female_neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>-62.691265</td>\n",
       "      <td>-61.921368</td>\n",
       "      <td>-58.112362</td>\n",
       "      <td>-55.378605</td>\n",
       "      <td>-56.545517</td>\n",
       "      <td>-58.246254</td>\n",
       "      <td>-58.498600</td>\n",
       "      <td>-58.577019</td>\n",
       "      <td>-59.843185</td>\n",
       "      <td>-59.149376</td>\n",
       "      <td>...</td>\n",
       "      <td>-56.717537</td>\n",
       "      <td>-58.949966</td>\n",
       "      <td>-57.629890</td>\n",
       "      <td>-59.174885</td>\n",
       "      <td>-58.905422</td>\n",
       "      <td>-57.774433</td>\n",
       "      <td>-63.483849</td>\n",
       "      <td>-65.929726</td>\n",
       "      <td>-64.601265</td>\n",
       "      <td>male_sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>-57.419632</td>\n",
       "      <td>-57.696335</td>\n",
       "      <td>-58.593155</td>\n",
       "      <td>-58.173706</td>\n",
       "      <td>-56.816082</td>\n",
       "      <td>-57.052647</td>\n",
       "      <td>-56.534256</td>\n",
       "      <td>-55.248650</td>\n",
       "      <td>-54.070976</td>\n",
       "      <td>-53.961277</td>\n",
       "      <td>...</td>\n",
       "      <td>-50.393684</td>\n",
       "      <td>-50.474960</td>\n",
       "      <td>-51.069885</td>\n",
       "      <td>-52.064430</td>\n",
       "      <td>-54.821354</td>\n",
       "      <td>-55.741508</td>\n",
       "      <td>-54.562801</td>\n",
       "      <td>-53.602413</td>\n",
       "      <td>-53.358292</td>\n",
       "      <td>female_fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1164</th>\n",
       "      <td>-53.474155</td>\n",
       "      <td>-53.511452</td>\n",
       "      <td>-52.082039</td>\n",
       "      <td>-50.696167</td>\n",
       "      <td>-50.189938</td>\n",
       "      <td>-50.134415</td>\n",
       "      <td>-50.680767</td>\n",
       "      <td>-51.942772</td>\n",
       "      <td>-53.169273</td>\n",
       "      <td>-53.600010</td>\n",
       "      <td>...</td>\n",
       "      <td>-62.197918</td>\n",
       "      <td>-62.197918</td>\n",
       "      <td>-62.198196</td>\n",
       "      <td>-62.179989</td>\n",
       "      <td>-61.918434</td>\n",
       "      <td>-62.197918</td>\n",
       "      <td>-62.197918</td>\n",
       "      <td>-62.197918</td>\n",
       "      <td>-62.197918</td>\n",
       "      <td>female_sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>-60.089787</td>\n",
       "      <td>-61.186764</td>\n",
       "      <td>-60.369534</td>\n",
       "      <td>-60.131462</td>\n",
       "      <td>-59.682110</td>\n",
       "      <td>-59.164402</td>\n",
       "      <td>-58.312378</td>\n",
       "      <td>-60.574406</td>\n",
       "      <td>-65.208549</td>\n",
       "      <td>-70.483025</td>\n",
       "      <td>...</td>\n",
       "      <td>-56.409870</td>\n",
       "      <td>-60.552391</td>\n",
       "      <td>-62.478554</td>\n",
       "      <td>-61.613541</td>\n",
       "      <td>-56.192425</td>\n",
       "      <td>-54.207466</td>\n",
       "      <td>-55.882080</td>\n",
       "      <td>-55.511684</td>\n",
       "      <td>-58.704964</td>\n",
       "      <td>male_fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1105</th>\n",
       "      <td>-55.102558</td>\n",
       "      <td>-56.048286</td>\n",
       "      <td>-58.384499</td>\n",
       "      <td>-61.521549</td>\n",
       "      <td>-64.581596</td>\n",
       "      <td>-64.264366</td>\n",
       "      <td>-63.681618</td>\n",
       "      <td>-61.965195</td>\n",
       "      <td>-63.487453</td>\n",
       "      <td>-64.640678</td>\n",
       "      <td>...</td>\n",
       "      <td>-51.864803</td>\n",
       "      <td>-52.473709</td>\n",
       "      <td>-51.908848</td>\n",
       "      <td>-54.379391</td>\n",
       "      <td>-53.660034</td>\n",
       "      <td>-53.956100</td>\n",
       "      <td>-52.871704</td>\n",
       "      <td>-51.789467</td>\n",
       "      <td>-52.396381</td>\n",
       "      <td>male_sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1043</th>\n",
       "      <td>-65.210434</td>\n",
       "      <td>-65.210434</td>\n",
       "      <td>-65.210434</td>\n",
       "      <td>-65.210434</td>\n",
       "      <td>-65.210434</td>\n",
       "      <td>-65.210434</td>\n",
       "      <td>-65.210434</td>\n",
       "      <td>-65.210434</td>\n",
       "      <td>-65.210434</td>\n",
       "      <td>-65.210434</td>\n",
       "      <td>...</td>\n",
       "      <td>-52.671288</td>\n",
       "      <td>-53.739876</td>\n",
       "      <td>-56.870102</td>\n",
       "      <td>-58.528603</td>\n",
       "      <td>-61.192078</td>\n",
       "      <td>-57.778610</td>\n",
       "      <td>-58.670589</td>\n",
       "      <td>-62.437386</td>\n",
       "      <td>-65.043129</td>\n",
       "      <td>female_sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1376</th>\n",
       "      <td>-51.901733</td>\n",
       "      <td>-51.953976</td>\n",
       "      <td>-51.834225</td>\n",
       "      <td>-51.816795</td>\n",
       "      <td>-52.076111</td>\n",
       "      <td>-52.105648</td>\n",
       "      <td>-51.473190</td>\n",
       "      <td>-50.890198</td>\n",
       "      <td>-50.660343</td>\n",
       "      <td>-51.521011</td>\n",
       "      <td>...</td>\n",
       "      <td>-53.263386</td>\n",
       "      <td>-53.263386</td>\n",
       "      <td>-53.226444</td>\n",
       "      <td>-52.401306</td>\n",
       "      <td>-52.240902</td>\n",
       "      <td>-51.482033</td>\n",
       "      <td>-52.637375</td>\n",
       "      <td>-52.970016</td>\n",
       "      <td>-53.263386</td>\n",
       "      <td>male_surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149</th>\n",
       "      <td>-79.454170</td>\n",
       "      <td>-79.454170</td>\n",
       "      <td>-79.454170</td>\n",
       "      <td>-79.454170</td>\n",
       "      <td>-79.454170</td>\n",
       "      <td>-79.454170</td>\n",
       "      <td>-79.454170</td>\n",
       "      <td>-79.454170</td>\n",
       "      <td>-79.454170</td>\n",
       "      <td>-79.454170</td>\n",
       "      <td>...</td>\n",
       "      <td>-37.341831</td>\n",
       "      <td>-37.588856</td>\n",
       "      <td>-37.900288</td>\n",
       "      <td>-37.453312</td>\n",
       "      <td>-37.783318</td>\n",
       "      <td>-38.713345</td>\n",
       "      <td>-39.685894</td>\n",
       "      <td>-38.186150</td>\n",
       "      <td>-35.537971</td>\n",
       "      <td>female_neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>-43.612679</td>\n",
       "      <td>-43.612679</td>\n",
       "      <td>-43.612679</td>\n",
       "      <td>-43.612679</td>\n",
       "      <td>-43.612679</td>\n",
       "      <td>-43.612679</td>\n",
       "      <td>-43.612679</td>\n",
       "      <td>-43.612679</td>\n",
       "      <td>-43.612679</td>\n",
       "      <td>-43.612679</td>\n",
       "      <td>...</td>\n",
       "      <td>-42.085365</td>\n",
       "      <td>-42.376163</td>\n",
       "      <td>-43.340157</td>\n",
       "      <td>-42.947365</td>\n",
       "      <td>-43.227009</td>\n",
       "      <td>-43.231194</td>\n",
       "      <td>-44.128220</td>\n",
       "      <td>-43.662796</td>\n",
       "      <td>-42.890789</td>\n",
       "      <td>female_angry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 217 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0          1          2          3          4          5  \\\n",
       "786  -68.854813 -68.854813 -68.854813 -68.854813 -68.854813 -68.854813   \n",
       "741  -62.691265 -61.921368 -58.112362 -55.378605 -56.545517 -58.246254   \n",
       "698  -57.419632 -57.696335 -58.593155 -58.173706 -56.816082 -57.052647   \n",
       "1164 -53.474155 -53.511452 -52.082039 -50.696167 -50.189938 -50.134415   \n",
       "518  -60.089787 -61.186764 -60.369534 -60.131462 -59.682110 -59.164402   \n",
       "1105 -55.102558 -56.048286 -58.384499 -61.521549 -64.581596 -64.264366   \n",
       "1043 -65.210434 -65.210434 -65.210434 -65.210434 -65.210434 -65.210434   \n",
       "1376 -51.901733 -51.953976 -51.834225 -51.816795 -52.076111 -52.105648   \n",
       "1149 -79.454170 -79.454170 -79.454170 -79.454170 -79.454170 -79.454170   \n",
       "214  -43.612679 -43.612679 -43.612679 -43.612679 -43.612679 -43.612679   \n",
       "\n",
       "              6          7          8          9  ...        207        208  \\\n",
       "786  -68.854813 -68.854813 -68.854813 -68.854813  ... -68.792786 -68.723152   \n",
       "741  -58.498600 -58.577019 -59.843185 -59.149376  ... -56.717537 -58.949966   \n",
       "698  -56.534256 -55.248650 -54.070976 -53.961277  ... -50.393684 -50.474960   \n",
       "1164 -50.680767 -51.942772 -53.169273 -53.600010  ... -62.197918 -62.197918   \n",
       "518  -58.312378 -60.574406 -65.208549 -70.483025  ... -56.409870 -60.552391   \n",
       "1105 -63.681618 -61.965195 -63.487453 -64.640678  ... -51.864803 -52.473709   \n",
       "1043 -65.210434 -65.210434 -65.210434 -65.210434  ... -52.671288 -53.739876   \n",
       "1376 -51.473190 -50.890198 -50.660343 -51.521011  ... -53.263386 -53.263386   \n",
       "1149 -79.454170 -79.454170 -79.454170 -79.454170  ... -37.341831 -37.588856   \n",
       "214  -43.612679 -43.612679 -43.612679 -43.612679  ... -42.085365 -42.376163   \n",
       "\n",
       "            209        210        211        212        213        214  \\\n",
       "786  -68.000206 -66.457191 -68.129662 -68.811119 -67.433525 -67.296227   \n",
       "741  -57.629890 -59.174885 -58.905422 -57.774433 -63.483849 -65.929726   \n",
       "698  -51.069885 -52.064430 -54.821354 -55.741508 -54.562801 -53.602413   \n",
       "1164 -62.198196 -62.179989 -61.918434 -62.197918 -62.197918 -62.197918   \n",
       "518  -62.478554 -61.613541 -56.192425 -54.207466 -55.882080 -55.511684   \n",
       "1105 -51.908848 -54.379391 -53.660034 -53.956100 -52.871704 -51.789467   \n",
       "1043 -56.870102 -58.528603 -61.192078 -57.778610 -58.670589 -62.437386   \n",
       "1376 -53.226444 -52.401306 -52.240902 -51.482033 -52.637375 -52.970016   \n",
       "1149 -37.900288 -37.453312 -37.783318 -38.713345 -39.685894 -38.186150   \n",
       "214  -43.340157 -42.947365 -43.227009 -43.231194 -44.128220 -43.662796   \n",
       "\n",
       "            215          labels  \n",
       "786  -68.486076  female_neutral  \n",
       "741  -64.601265        male_sad  \n",
       "698  -53.358292     female_fear  \n",
       "1164 -62.197918      female_sad  \n",
       "518  -58.704964       male_fear  \n",
       "1105 -52.396381        male_sad  \n",
       "1043 -65.043129      female_sad  \n",
       "1376 -53.263386   male_surprise  \n",
       "1149 -35.537971  female_neutral  \n",
       "214  -42.890789    female_angry  \n",
       "\n",
       "[10 rows x 217 columns]"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "rnewdf = shuffle(newdf)\n",
    "rnewdf[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnewdf=rnewdf.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividing the data into test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf1 = np.random.rand(len(rnewdf)) < 0.8\n",
    "train = rnewdf[newdf1]\n",
    "test = rnewdf[~newdf1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>-51.358871</td>\n",
       "      <td>-51.638977</td>\n",
       "      <td>-51.997269</td>\n",
       "      <td>-51.910355</td>\n",
       "      <td>-51.692856</td>\n",
       "      <td>-51.664940</td>\n",
       "      <td>-51.767826</td>\n",
       "      <td>-51.822567</td>\n",
       "      <td>-52.103909</td>\n",
       "      <td>-52.059486</td>\n",
       "      <td>...</td>\n",
       "      <td>-49.337711</td>\n",
       "      <td>-50.789944</td>\n",
       "      <td>-50.442051</td>\n",
       "      <td>-51.949978</td>\n",
       "      <td>-50.959999</td>\n",
       "      <td>-50.434090</td>\n",
       "      <td>-50.234821</td>\n",
       "      <td>-51.110268</td>\n",
       "      <td>-51.266232</td>\n",
       "      <td>female_fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>-65.012177</td>\n",
       "      <td>-62.332249</td>\n",
       "      <td>-65.145363</td>\n",
       "      <td>-74.183067</td>\n",
       "      <td>-77.810989</td>\n",
       "      <td>-77.903465</td>\n",
       "      <td>-78.839149</td>\n",
       "      <td>-77.973900</td>\n",
       "      <td>-69.871590</td>\n",
       "      <td>-62.527519</td>\n",
       "      <td>...</td>\n",
       "      <td>-62.252056</td>\n",
       "      <td>-65.876846</td>\n",
       "      <td>-67.579140</td>\n",
       "      <td>-61.824150</td>\n",
       "      <td>-62.076839</td>\n",
       "      <td>-65.980927</td>\n",
       "      <td>-67.948471</td>\n",
       "      <td>-71.522568</td>\n",
       "      <td>-76.508499</td>\n",
       "      <td>male_sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>-57.254601</td>\n",
       "      <td>-57.254601</td>\n",
       "      <td>-57.254601</td>\n",
       "      <td>-57.254601</td>\n",
       "      <td>-56.735863</td>\n",
       "      <td>-56.598503</td>\n",
       "      <td>-57.254601</td>\n",
       "      <td>-57.254601</td>\n",
       "      <td>-57.254601</td>\n",
       "      <td>-57.254601</td>\n",
       "      <td>...</td>\n",
       "      <td>-45.593632</td>\n",
       "      <td>-46.054928</td>\n",
       "      <td>-45.883911</td>\n",
       "      <td>-46.726562</td>\n",
       "      <td>-46.430088</td>\n",
       "      <td>-47.236164</td>\n",
       "      <td>-49.231026</td>\n",
       "      <td>-47.199142</td>\n",
       "      <td>-46.399151</td>\n",
       "      <td>male_surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>-55.477638</td>\n",
       "      <td>-55.023621</td>\n",
       "      <td>-53.268936</td>\n",
       "      <td>-52.932861</td>\n",
       "      <td>-52.404671</td>\n",
       "      <td>-52.209049</td>\n",
       "      <td>-52.069626</td>\n",
       "      <td>-53.098457</td>\n",
       "      <td>-53.062256</td>\n",
       "      <td>-52.698025</td>\n",
       "      <td>...</td>\n",
       "      <td>-54.063232</td>\n",
       "      <td>-54.588745</td>\n",
       "      <td>-55.305439</td>\n",
       "      <td>-54.877872</td>\n",
       "      <td>-54.315720</td>\n",
       "      <td>-54.058735</td>\n",
       "      <td>-53.360317</td>\n",
       "      <td>-52.790226</td>\n",
       "      <td>-53.169960</td>\n",
       "      <td>male_surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1080</th>\n",
       "      <td>-63.393501</td>\n",
       "      <td>-60.851528</td>\n",
       "      <td>-58.837444</td>\n",
       "      <td>-59.027035</td>\n",
       "      <td>-58.936684</td>\n",
       "      <td>-55.688091</td>\n",
       "      <td>-53.725571</td>\n",
       "      <td>-53.267906</td>\n",
       "      <td>-52.348530</td>\n",
       "      <td>-51.438309</td>\n",
       "      <td>...</td>\n",
       "      <td>-58.230343</td>\n",
       "      <td>-59.048733</td>\n",
       "      <td>-62.915852</td>\n",
       "      <td>-62.098450</td>\n",
       "      <td>-59.426155</td>\n",
       "      <td>-58.405361</td>\n",
       "      <td>-56.096516</td>\n",
       "      <td>-56.379257</td>\n",
       "      <td>-58.569496</td>\n",
       "      <td>male_neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>-47.939163</td>\n",
       "      <td>-47.939163</td>\n",
       "      <td>-47.939163</td>\n",
       "      <td>-47.939163</td>\n",
       "      <td>-47.939163</td>\n",
       "      <td>-47.939163</td>\n",
       "      <td>-47.939163</td>\n",
       "      <td>-47.939163</td>\n",
       "      <td>-47.939163</td>\n",
       "      <td>-47.939163</td>\n",
       "      <td>...</td>\n",
       "      <td>-39.217300</td>\n",
       "      <td>-41.336365</td>\n",
       "      <td>-43.327106</td>\n",
       "      <td>-44.894978</td>\n",
       "      <td>-46.341667</td>\n",
       "      <td>-46.351433</td>\n",
       "      <td>-46.122211</td>\n",
       "      <td>-45.831158</td>\n",
       "      <td>-45.531868</td>\n",
       "      <td>female_happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038</th>\n",
       "      <td>-49.566441</td>\n",
       "      <td>-47.824402</td>\n",
       "      <td>-46.220272</td>\n",
       "      <td>-45.217979</td>\n",
       "      <td>-43.194168</td>\n",
       "      <td>-42.643661</td>\n",
       "      <td>-43.485649</td>\n",
       "      <td>-44.540710</td>\n",
       "      <td>-45.943306</td>\n",
       "      <td>-47.248997</td>\n",
       "      <td>...</td>\n",
       "      <td>-41.133945</td>\n",
       "      <td>-41.743568</td>\n",
       "      <td>-40.540928</td>\n",
       "      <td>-42.072590</td>\n",
       "      <td>-45.595589</td>\n",
       "      <td>-48.221561</td>\n",
       "      <td>-48.224663</td>\n",
       "      <td>-48.336758</td>\n",
       "      <td>-48.210957</td>\n",
       "      <td>female_happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>-46.456722</td>\n",
       "      <td>-47.024208</td>\n",
       "      <td>-46.142891</td>\n",
       "      <td>-46.262917</td>\n",
       "      <td>-46.480350</td>\n",
       "      <td>-46.620781</td>\n",
       "      <td>-47.260395</td>\n",
       "      <td>-46.667107</td>\n",
       "      <td>-47.757442</td>\n",
       "      <td>-46.490688</td>\n",
       "      <td>...</td>\n",
       "      <td>-45.584675</td>\n",
       "      <td>-43.598022</td>\n",
       "      <td>-46.936813</td>\n",
       "      <td>-47.840897</td>\n",
       "      <td>-48.035347</td>\n",
       "      <td>-47.782524</td>\n",
       "      <td>-45.367897</td>\n",
       "      <td>-45.400932</td>\n",
       "      <td>-47.511482</td>\n",
       "      <td>female_sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>-53.141987</td>\n",
       "      <td>-52.674992</td>\n",
       "      <td>-50.214226</td>\n",
       "      <td>-50.819004</td>\n",
       "      <td>-54.603825</td>\n",
       "      <td>-52.255264</td>\n",
       "      <td>-50.683800</td>\n",
       "      <td>-52.724796</td>\n",
       "      <td>-49.598228</td>\n",
       "      <td>-51.657570</td>\n",
       "      <td>...</td>\n",
       "      <td>-47.976353</td>\n",
       "      <td>-47.613281</td>\n",
       "      <td>-48.414055</td>\n",
       "      <td>-49.194748</td>\n",
       "      <td>-50.277706</td>\n",
       "      <td>-52.465252</td>\n",
       "      <td>-54.078613</td>\n",
       "      <td>-56.517986</td>\n",
       "      <td>-57.023308</td>\n",
       "      <td>male_happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>-54.384609</td>\n",
       "      <td>-54.384609</td>\n",
       "      <td>-54.384609</td>\n",
       "      <td>-54.384609</td>\n",
       "      <td>-54.384609</td>\n",
       "      <td>-54.384609</td>\n",
       "      <td>-54.384609</td>\n",
       "      <td>-54.384609</td>\n",
       "      <td>-54.384609</td>\n",
       "      <td>-54.384609</td>\n",
       "      <td>...</td>\n",
       "      <td>-54.320442</td>\n",
       "      <td>-54.153461</td>\n",
       "      <td>-54.013290</td>\n",
       "      <td>-52.559669</td>\n",
       "      <td>-52.440292</td>\n",
       "      <td>-52.519524</td>\n",
       "      <td>-53.176575</td>\n",
       "      <td>-52.175941</td>\n",
       "      <td>-52.257362</td>\n",
       "      <td>female_sad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 217 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0          1          2          3          4          5  \\\n",
       "102  -51.358871 -51.638977 -51.997269 -51.910355 -51.692856 -51.664940   \n",
       "260  -65.012177 -62.332249 -65.145363 -74.183067 -77.810989 -77.903465   \n",
       "419  -57.254601 -57.254601 -57.254601 -57.254601 -56.735863 -56.598503   \n",
       "1258 -55.477638 -55.023621 -53.268936 -52.932861 -52.404671 -52.209049   \n",
       "1080 -63.393501 -60.851528 -58.837444 -59.027035 -58.936684 -55.688091   \n",
       "798  -47.939163 -47.939163 -47.939163 -47.939163 -47.939163 -47.939163   \n",
       "1038 -49.566441 -47.824402 -46.220272 -45.217979 -43.194168 -42.643661   \n",
       "685  -46.456722 -47.024208 -46.142891 -46.262917 -46.480350 -46.620781   \n",
       "974  -53.141987 -52.674992 -50.214226 -50.819004 -54.603825 -52.255264   \n",
       "204  -54.384609 -54.384609 -54.384609 -54.384609 -54.384609 -54.384609   \n",
       "\n",
       "              6          7          8          9  ...        207        208  \\\n",
       "102  -51.767826 -51.822567 -52.103909 -52.059486  ... -49.337711 -50.789944   \n",
       "260  -78.839149 -77.973900 -69.871590 -62.527519  ... -62.252056 -65.876846   \n",
       "419  -57.254601 -57.254601 -57.254601 -57.254601  ... -45.593632 -46.054928   \n",
       "1258 -52.069626 -53.098457 -53.062256 -52.698025  ... -54.063232 -54.588745   \n",
       "1080 -53.725571 -53.267906 -52.348530 -51.438309  ... -58.230343 -59.048733   \n",
       "798  -47.939163 -47.939163 -47.939163 -47.939163  ... -39.217300 -41.336365   \n",
       "1038 -43.485649 -44.540710 -45.943306 -47.248997  ... -41.133945 -41.743568   \n",
       "685  -47.260395 -46.667107 -47.757442 -46.490688  ... -45.584675 -43.598022   \n",
       "974  -50.683800 -52.724796 -49.598228 -51.657570  ... -47.976353 -47.613281   \n",
       "204  -54.384609 -54.384609 -54.384609 -54.384609  ... -54.320442 -54.153461   \n",
       "\n",
       "            209        210        211        212        213        214  \\\n",
       "102  -50.442051 -51.949978 -50.959999 -50.434090 -50.234821 -51.110268   \n",
       "260  -67.579140 -61.824150 -62.076839 -65.980927 -67.948471 -71.522568   \n",
       "419  -45.883911 -46.726562 -46.430088 -47.236164 -49.231026 -47.199142   \n",
       "1258 -55.305439 -54.877872 -54.315720 -54.058735 -53.360317 -52.790226   \n",
       "1080 -62.915852 -62.098450 -59.426155 -58.405361 -56.096516 -56.379257   \n",
       "798  -43.327106 -44.894978 -46.341667 -46.351433 -46.122211 -45.831158   \n",
       "1038 -40.540928 -42.072590 -45.595589 -48.221561 -48.224663 -48.336758   \n",
       "685  -46.936813 -47.840897 -48.035347 -47.782524 -45.367897 -45.400932   \n",
       "974  -48.414055 -49.194748 -50.277706 -52.465252 -54.078613 -56.517986   \n",
       "204  -54.013290 -52.559669 -52.440292 -52.519524 -53.176575 -52.175941   \n",
       "\n",
       "            215         labels  \n",
       "102  -51.266232    female_fear  \n",
       "260  -76.508499       male_sad  \n",
       "419  -46.399151  male_surprise  \n",
       "1258 -53.169960  male_surprise  \n",
       "1080 -58.569496   male_neutral  \n",
       "798  -45.531868   female_happy  \n",
       "1038 -48.210957   female_happy  \n",
       "685  -47.511482     female_sad  \n",
       "974  -57.023308     male_happy  \n",
       "204  -52.257362     female_sad  \n",
       "\n",
       "[10 rows x 217 columns]"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[250:260]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainfeatures = train.iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainlabel = train.iloc[:, -1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "testfeatures = test.iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "testlabel = test.iloc[:, -1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colot\\anaconda3\\envs\\cz4042\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "X_train = np.array(trainfeatures)\n",
    "y_train = np.array(trainlabel)\n",
    "X_test = np.array(testfeatures)\n",
    "y_test = np.array(testlabel)\n",
    "\n",
    "lb = LabelEncoder()\n",
    "\n",
    "y_train = np_utils.to_categorical(lb.fit_transform(y_train))\n",
    "y_test = np_utils.to_categorical(lb.fit_transform(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1151, 216)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing dimension for CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_traincnn =np.expand_dims(X_train, axis=2)\n",
    "x_testcnn= np.expand_dims(X_test, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(256, 5,padding='same',\n",
    "                 input_shape=(216,1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 5,padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(MaxPooling1D(pool_size=(8)))\n",
    "model.add(Conv1D(128, 5,padding='same',))\n",
    "model.add(Activation('relu'))\n",
    "#model.add(Conv1D(128, 5,padding='same',))\n",
    "#model.add(Activation('relu'))\n",
    "#model.add(Conv1D(128, 5,padding='same',))\n",
    "#model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Conv1D(128, 5,padding='same',))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(14))\n",
    "model.add(Activation('softmax'))\n",
    "opt = optimizers.RMSprop(lr=0.00001, decay=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_44 (Conv1D)           (None, 216, 256)          1536      \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 216, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_45 (Conv1D)           (None, 216, 128)          163968    \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 216, 128)          0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 216, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 27, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_46 (Conv1D)           (None, 27, 128)           82048     \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 27, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_47 (Conv1D)           (None, 27, 128)           82048     \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 27, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 3456)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 14)                48398     \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 14)                0         \n",
      "=================================================================\n",
      "Total params: 377,998\n",
      "Trainable params: 377,998\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removed the whole training part for avoiding unnecessary long epochs list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/700\n",
      "72/72 [==============================] - 5s 59ms/step - loss: 2.9955 - accuracy: 0.0791 - val_loss: 2.6412 - val_accuracy: 0.1280\n",
      "Epoch 2/700\n",
      "72/72 [==============================] - 4s 58ms/step - loss: 2.5920 - accuracy: 0.1260 - val_loss: 2.5697 - val_accuracy: 0.1211\n",
      "Epoch 3/700\n",
      "72/72 [==============================] - 4s 56ms/step - loss: 2.5541 - accuracy: 0.1390 - val_loss: 2.5311 - val_accuracy: 0.1419\n",
      "Epoch 4/700\n",
      "72/72 [==============================] - 4s 57ms/step - loss: 2.5245 - accuracy: 0.1477 - val_loss: 2.5033 - val_accuracy: 0.1626\n",
      "Epoch 5/700\n",
      "72/72 [==============================] - 4s 61ms/step - loss: 2.4991 - accuracy: 0.1529 - val_loss: 2.4886 - val_accuracy: 0.1869\n",
      "Epoch 6/700\n",
      "72/72 [==============================] - 4s 62ms/step - loss: 2.4725 - accuracy: 0.1668 - val_loss: 2.4665 - val_accuracy: 0.1661\n",
      "Epoch 7/700\n",
      "72/72 [==============================] - 4s 62ms/step - loss: 2.4519 - accuracy: 0.1807 - val_loss: 2.4407 - val_accuracy: 0.2111\n",
      "Epoch 8/700\n",
      "72/72 [==============================] - 4s 60ms/step - loss: 2.4265 - accuracy: 0.1929 - val_loss: 2.4466 - val_accuracy: 0.1661\n",
      "Epoch 9/700\n",
      "72/72 [==============================] - 5s 68ms/step - loss: 2.4036 - accuracy: 0.2050 - val_loss: 2.4133 - val_accuracy: 0.2007\n",
      "Epoch 10/700\n",
      "72/72 [==============================] - 5s 67ms/step - loss: 2.3806 - accuracy: 0.2137 - val_loss: 2.4058 - val_accuracy: 0.1834\n",
      "Epoch 11/700\n",
      "72/72 [==============================] - 4s 61ms/step - loss: 2.3599 - accuracy: 0.2155 - val_loss: 2.3986 - val_accuracy: 0.1765\n",
      "Epoch 12/700\n",
      "72/72 [==============================] - 4s 60ms/step - loss: 2.3413 - accuracy: 0.2311 - val_loss: 2.3689 - val_accuracy: 0.2145\n",
      "Epoch 13/700\n",
      "72/72 [==============================] - 4s 61ms/step - loss: 2.3212 - accuracy: 0.2389 - val_loss: 2.3601 - val_accuracy: 0.2180\n",
      "Epoch 14/700\n",
      "72/72 [==============================] - 4s 62ms/step - loss: 2.2944 - accuracy: 0.2433 - val_loss: 2.3291 - val_accuracy: 0.2388\n",
      "Epoch 15/700\n",
      "72/72 [==============================] - 4s 59ms/step - loss: 2.2854 - accuracy: 0.2372 - val_loss: 2.3144 - val_accuracy: 0.2353\n",
      "Epoch 16/700\n",
      "72/72 [==============================] - 4s 55ms/step - loss: 2.2635 - accuracy: 0.2598 - val_loss: 2.3119 - val_accuracy: 0.2076\n",
      "Epoch 17/700\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 2.2400 - accuracy: 0.2485 - val_loss: 2.2842 - val_accuracy: 0.2422\n",
      "Epoch 18/700\n",
      "72/72 [==============================] - 4s 55ms/step - loss: 2.2216 - accuracy: 0.2632 - val_loss: 2.2835 - val_accuracy: 0.2215\n",
      "Epoch 19/700\n",
      "72/72 [==============================] - 4s 55ms/step - loss: 2.2113 - accuracy: 0.2728 - val_loss: 2.2513 - val_accuracy: 0.2630\n",
      "Epoch 20/700\n",
      "72/72 [==============================] - 5s 65ms/step - loss: 2.1917 - accuracy: 0.2754 - val_loss: 2.2427 - val_accuracy: 0.2837\n",
      "Epoch 21/700\n",
      "72/72 [==============================] - 4s 55ms/step - loss: 2.1738 - accuracy: 0.2832 - val_loss: 2.2369 - val_accuracy: 0.2561\n",
      "Epoch 22/700\n",
      "72/72 [==============================] - 4s 62ms/step - loss: 2.1612 - accuracy: 0.2754 - val_loss: 2.2377 - val_accuracy: 0.2422\n",
      "Epoch 23/700\n",
      "72/72 [==============================] - 4s 61ms/step - loss: 2.1401 - accuracy: 0.2928 - val_loss: 2.2271 - val_accuracy: 0.2699\n",
      "Epoch 24/700\n",
      "72/72 [==============================] - 5s 66ms/step - loss: 2.1352 - accuracy: 0.2928 - val_loss: 2.2047 - val_accuracy: 0.2664\n",
      "Epoch 25/700\n",
      "72/72 [==============================] - 5s 65ms/step - loss: 2.1158 - accuracy: 0.2937 - val_loss: 2.1659 - val_accuracy: 0.2803\n",
      "Epoch 26/700\n",
      "72/72 [==============================] - 5s 72ms/step - loss: 2.0950 - accuracy: 0.2997 - val_loss: 2.1696 - val_accuracy: 0.2837\n",
      "Epoch 27/700\n",
      "72/72 [==============================] - 4s 59ms/step - loss: 2.0862 - accuracy: 0.3041 - val_loss: 2.1576 - val_accuracy: 0.2699\n",
      "Epoch 28/700\n",
      "72/72 [==============================] - 4s 58ms/step - loss: 2.0655 - accuracy: 0.3275 - val_loss: 2.1418 - val_accuracy: 0.2664\n",
      "Epoch 29/700\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 2.0561 - accuracy: 0.3145 - val_loss: 2.1355 - val_accuracy: 0.3080\n",
      "Epoch 30/700\n",
      "72/72 [==============================] - 4s 60ms/step - loss: 2.0403 - accuracy: 0.3275 - val_loss: 2.1283 - val_accuracy: 0.2803\n",
      "Epoch 31/700\n",
      "72/72 [==============================] - 5s 65ms/step - loss: 2.0234 - accuracy: 0.3284 - val_loss: 2.1043 - val_accuracy: 0.3010\n",
      "Epoch 32/700\n",
      "72/72 [==============================] - 4s 62ms/step - loss: 2.0126 - accuracy: 0.3267 - val_loss: 2.1057 - val_accuracy: 0.2837\n",
      "Epoch 33/700\n",
      "72/72 [==============================] - 4s 62ms/step - loss: 1.9984 - accuracy: 0.3267 - val_loss: 2.1268 - val_accuracy: 0.2803\n",
      "Epoch 34/700\n",
      "72/72 [==============================] - 5s 63ms/step - loss: 1.9844 - accuracy: 0.3354 - val_loss: 2.1019 - val_accuracy: 0.3080\n",
      "Epoch 35/700\n",
      "72/72 [==============================] - 4s 59ms/step - loss: 1.9673 - accuracy: 0.3388 - val_loss: 2.1259 - val_accuracy: 0.2388\n",
      "Epoch 36/700\n",
      "72/72 [==============================] - 4s 62ms/step - loss: 1.9606 - accuracy: 0.3345 - val_loss: 2.0812 - val_accuracy: 0.3114\n",
      "Epoch 37/700\n",
      "72/72 [==============================] - 5s 63ms/step - loss: 1.9481 - accuracy: 0.3449 - val_loss: 2.0790 - val_accuracy: 0.2907\n",
      "Epoch 38/700\n",
      "72/72 [==============================] - 5s 64ms/step - loss: 1.9384 - accuracy: 0.3519 - val_loss: 2.0703 - val_accuracy: 0.3010\n",
      "Epoch 39/700\n",
      "72/72 [==============================] - 5s 65ms/step - loss: 1.9187 - accuracy: 0.3640 - val_loss: 2.0758 - val_accuracy: 0.3149\n",
      "Epoch 40/700\n",
      "72/72 [==============================] - 5s 70ms/step - loss: 1.9140 - accuracy: 0.3545 - val_loss: 2.0584 - val_accuracy: 0.2837\n",
      "Epoch 41/700\n",
      "72/72 [==============================] - 5s 66ms/step - loss: 1.8991 - accuracy: 0.3588 - val_loss: 2.0759 - val_accuracy: 0.2976\n",
      "Epoch 42/700\n",
      "72/72 [==============================] - 5s 73ms/step - loss: 1.8903 - accuracy: 0.3692 - val_loss: 2.0404 - val_accuracy: 0.3183\n",
      "Epoch 43/700\n",
      "72/72 [==============================] - 5s 66ms/step - loss: 1.8806 - accuracy: 0.3562 - val_loss: 2.0111 - val_accuracy: 0.3287\n",
      "Epoch 44/700\n",
      "72/72 [==============================] - 4s 56ms/step - loss: 1.8737 - accuracy: 0.3658 - val_loss: 2.0075 - val_accuracy: 0.3114\n",
      "Epoch 45/700\n",
      "72/72 [==============================] - 4s 56ms/step - loss: 1.8708 - accuracy: 0.3449 - val_loss: 2.0233 - val_accuracy: 0.3287\n",
      "Epoch 46/700\n",
      "72/72 [==============================] - 5s 63ms/step - loss: 1.8554 - accuracy: 0.3684 - val_loss: 1.9984 - val_accuracy: 0.3149\n",
      "Epoch 47/700\n",
      "72/72 [==============================] - 4s 58ms/step - loss: 1.8455 - accuracy: 0.3684 - val_loss: 1.9995 - val_accuracy: 0.3287\n",
      "Epoch 48/700\n",
      "72/72 [==============================] - 4s 55ms/step - loss: 1.8391 - accuracy: 0.3692 - val_loss: 1.9923 - val_accuracy: 0.2976\n",
      "Epoch 49/700\n",
      "72/72 [==============================] - 4s 62ms/step - loss: 1.8215 - accuracy: 0.3736 - val_loss: 1.9815 - val_accuracy: 0.3322\n",
      "Epoch 50/700\n",
      "72/72 [==============================] - 5s 69ms/step - loss: 1.8169 - accuracy: 0.3918 - val_loss: 1.9898 - val_accuracy: 0.3218\n",
      "Epoch 51/700\n",
      "72/72 [==============================] - 4s 61ms/step - loss: 1.8044 - accuracy: 0.3858 - val_loss: 2.0012 - val_accuracy: 0.2976\n",
      "Epoch 52/700\n",
      "72/72 [==============================] - 4s 60ms/step - loss: 1.8017 - accuracy: 0.3727 - val_loss: 1.9598 - val_accuracy: 0.3253\n",
      "Epoch 53/700\n",
      "72/72 [==============================] - 4s 60ms/step - loss: 1.7956 - accuracy: 0.3805 - val_loss: 1.9791 - val_accuracy: 0.2907\n",
      "Epoch 54/700\n",
      "72/72 [==============================] - 4s 59ms/step - loss: 1.7816 - accuracy: 0.3753 - val_loss: 2.0351 - val_accuracy: 0.2837\n",
      "Epoch 55/700\n",
      "72/72 [==============================] - 4s 60ms/step - loss: 1.7694 - accuracy: 0.3858 - val_loss: 1.9590 - val_accuracy: 0.3322\n",
      "Epoch 56/700\n",
      "72/72 [==============================] - 4s 61ms/step - loss: 1.7757 - accuracy: 0.3805 - val_loss: 1.9610 - val_accuracy: 0.3356\n",
      "Epoch 57/700\n",
      "72/72 [==============================] - 5s 65ms/step - loss: 1.7660 - accuracy: 0.3936 - val_loss: 1.9450 - val_accuracy: 0.3322\n",
      "Epoch 58/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 4s 62ms/step - loss: 1.7481 - accuracy: 0.3979 - val_loss: 1.9662 - val_accuracy: 0.3114\n",
      "Epoch 59/700\n",
      "72/72 [==============================] - 4s 59ms/step - loss: 1.7448 - accuracy: 0.3858 - val_loss: 1.9245 - val_accuracy: 0.3599\n",
      "Epoch 60/700\n",
      "72/72 [==============================] - 4s 60ms/step - loss: 1.7439 - accuracy: 0.4023 - val_loss: 1.9057 - val_accuracy: 0.3287\n",
      "Epoch 61/700\n",
      "72/72 [==============================] - 4s 59ms/step - loss: 1.7375 - accuracy: 0.3892 - val_loss: 1.9213 - val_accuracy: 0.3426\n",
      "Epoch 62/700\n",
      "72/72 [==============================] - 4s 58ms/step - loss: 1.7267 - accuracy: 0.4101 - val_loss: 1.9514 - val_accuracy: 0.3080\n",
      "Epoch 63/700\n",
      "72/72 [==============================] - 5s 63ms/step - loss: 1.7211 - accuracy: 0.4040 - val_loss: 1.9245 - val_accuracy: 0.3391\n",
      "Epoch 64/700\n",
      "72/72 [==============================] - 5s 65ms/step - loss: 1.7121 - accuracy: 0.4066 - val_loss: 1.9112 - val_accuracy: 0.3391\n",
      "Epoch 65/700\n",
      "72/72 [==============================] - 4s 58ms/step - loss: 1.7058 - accuracy: 0.4066 - val_loss: 1.9457 - val_accuracy: 0.3114\n",
      "Epoch 66/700\n",
      "72/72 [==============================] - 5s 71ms/step - loss: 1.7011 - accuracy: 0.4231 - val_loss: 1.9153 - val_accuracy: 0.3322\n",
      "Epoch 67/700\n",
      "72/72 [==============================] - 5s 67ms/step - loss: 1.7010 - accuracy: 0.3988 - val_loss: 1.9035 - val_accuracy: 0.3391\n",
      "Epoch 68/700\n",
      "72/72 [==============================] - 5s 68ms/step - loss: 1.7006 - accuracy: 0.4136 - val_loss: 1.8845 - val_accuracy: 0.3287\n",
      "Epoch 69/700\n",
      "72/72 [==============================] - 5s 66ms/step - loss: 1.6845 - accuracy: 0.4083 - val_loss: 1.8932 - val_accuracy: 0.3599\n",
      "Epoch 70/700\n",
      "72/72 [==============================] - 5s 63ms/step - loss: 1.6849 - accuracy: 0.4066 - val_loss: 1.8961 - val_accuracy: 0.3529\n",
      "Epoch 71/700\n",
      "72/72 [==============================] - 5s 64ms/step - loss: 1.6706 - accuracy: 0.4170 - val_loss: 1.9063 - val_accuracy: 0.3356\n",
      "Epoch 72/700\n",
      "72/72 [==============================] - 4s 60ms/step - loss: 1.6747 - accuracy: 0.4214 - val_loss: 1.8826 - val_accuracy: 0.3599\n",
      "Epoch 73/700\n",
      "72/72 [==============================] - 4s 59ms/step - loss: 1.6619 - accuracy: 0.4136 - val_loss: 1.9115 - val_accuracy: 0.3287\n",
      "Epoch 74/700\n",
      "72/72 [==============================] - 4s 60ms/step - loss: 1.6612 - accuracy: 0.4127 - val_loss: 1.8860 - val_accuracy: 0.3668\n",
      "Epoch 75/700\n",
      "72/72 [==============================] - 4s 55ms/step - loss: 1.6567 - accuracy: 0.4144 - val_loss: 1.8816 - val_accuracy: 0.3495\n",
      "Epoch 76/700\n",
      "72/72 [==============================] - 4s 58ms/step - loss: 1.6541 - accuracy: 0.4144 - val_loss: 1.8699 - val_accuracy: 0.3564\n",
      "Epoch 77/700\n",
      "72/72 [==============================] - 4s 62ms/step - loss: 1.6447 - accuracy: 0.4118 - val_loss: 1.8825 - val_accuracy: 0.3702\n",
      "Epoch 78/700\n",
      "72/72 [==============================] - 4s 56ms/step - loss: 1.6334 - accuracy: 0.4231 - val_loss: 1.8749 - val_accuracy: 0.3702\n",
      "Epoch 79/700\n",
      "72/72 [==============================] - 4s 59ms/step - loss: 1.6353 - accuracy: 0.4257 - val_loss: 1.9167 - val_accuracy: 0.3114\n",
      "Epoch 80/700\n",
      "72/72 [==============================] - 4s 58ms/step - loss: 1.6342 - accuracy: 0.4109 - val_loss: 1.8648 - val_accuracy: 0.3737\n",
      "Epoch 81/700\n",
      "72/72 [==============================] - 4s 58ms/step - loss: 1.6255 - accuracy: 0.4092 - val_loss: 1.9041 - val_accuracy: 0.3114\n",
      "Epoch 82/700\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 1.6268 - accuracy: 0.4353 - val_loss: 1.8704 - val_accuracy: 0.3495\n",
      "Epoch 83/700\n",
      "72/72 [==============================] - 4s 56ms/step - loss: 1.6214 - accuracy: 0.4396 - val_loss: 1.9002 - val_accuracy: 0.3149\n",
      "Epoch 84/700\n",
      "72/72 [==============================] - 5s 64ms/step - loss: 1.6128 - accuracy: 0.4448 - val_loss: 1.8758 - val_accuracy: 0.3564\n",
      "Epoch 85/700\n",
      "72/72 [==============================] - 4s 62ms/step - loss: 1.6060 - accuracy: 0.4405 - val_loss: 1.8941 - val_accuracy: 0.3080\n",
      "Epoch 86/700\n",
      "72/72 [==============================] - 4s 62ms/step - loss: 1.6026 - accuracy: 0.4370 - val_loss: 1.8615 - val_accuracy: 0.3183\n",
      "Epoch 87/700\n",
      "72/72 [==============================] - 5s 63ms/step - loss: 1.6058 - accuracy: 0.4379 - val_loss: 1.8683 - val_accuracy: 0.3460\n",
      "Epoch 88/700\n",
      "72/72 [==============================] - 5s 64ms/step - loss: 1.5949 - accuracy: 0.4335 - val_loss: 1.8760 - val_accuracy: 0.3287\n",
      "Epoch 89/700\n",
      "72/72 [==============================] - 4s 57ms/step - loss: 1.5973 - accuracy: 0.4387 - val_loss: 1.8649 - val_accuracy: 0.3426\n",
      "Epoch 90/700\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 1.5863 - accuracy: 0.4431 - val_loss: 1.8634 - val_accuracy: 0.3564\n",
      "Epoch 91/700\n",
      "72/72 [==============================] - 4s 55ms/step - loss: 1.5866 - accuracy: 0.4492 - val_loss: 1.9303 - val_accuracy: 0.3114\n",
      "Epoch 92/700\n",
      "72/72 [==============================] - 4s 55ms/step - loss: 1.5867 - accuracy: 0.4396 - val_loss: 1.8929 - val_accuracy: 0.3183\n",
      "Epoch 93/700\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 1.5846 - accuracy: 0.4387 - val_loss: 1.8820 - val_accuracy: 0.3045\n",
      "Epoch 94/700\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 1.5737 - accuracy: 0.4526 - val_loss: 1.8446 - val_accuracy: 0.3737\n",
      "Epoch 95/700\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 1.5720 - accuracy: 0.4509 - val_loss: 1.8442 - val_accuracy: 0.3529\n",
      "Epoch 96/700\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 1.5639 - accuracy: 0.4509 - val_loss: 1.8400 - val_accuracy: 0.3668\n",
      "Epoch 97/700\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 1.5663 - accuracy: 0.4509 - val_loss: 1.8746 - val_accuracy: 0.3114\n",
      "Epoch 98/700\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 1.5545 - accuracy: 0.4570 - val_loss: 1.8770 - val_accuracy: 0.3599\n",
      "Epoch 99/700\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 1.5571 - accuracy: 0.4483 - val_loss: 1.8295 - val_accuracy: 0.3668\n",
      "Epoch 100/700\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 1.5575 - accuracy: 0.4631 - val_loss: 1.8549 - val_accuracy: 0.3426\n",
      "Epoch 101/700\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 1.5452 - accuracy: 0.4500 - val_loss: 1.8591 - val_accuracy: 0.3149\n",
      "Epoch 102/700\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 1.5424 - accuracy: 0.4631 - val_loss: 1.8832 - val_accuracy: 0.3183\n",
      "Epoch 103/700\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 1.5353 - accuracy: 0.4526 - val_loss: 1.8642 - val_accuracy: 0.3426\n",
      "Epoch 104/700\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 1.5354 - accuracy: 0.4526 - val_loss: 1.8734 - val_accuracy: 0.3287\n",
      "Epoch 105/700\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 1.5277 - accuracy: 0.4674 - val_loss: 1.8582 - val_accuracy: 0.3495\n",
      "Epoch 106/700\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 1.5314 - accuracy: 0.4709 - val_loss: 1.8436 - val_accuracy: 0.3391\n",
      "Epoch 107/700\n",
      "72/72 [==============================] - 4s 55ms/step - loss: 1.5242 - accuracy: 0.4709 - val_loss: 1.8908 - val_accuracy: 0.3253\n",
      "Epoch 108/700\n",
      "72/72 [==============================] - 4s 58ms/step - loss: 1.5222 - accuracy: 0.4553 - val_loss: 1.8342 - val_accuracy: 0.3460\n",
      "Epoch 109/700\n",
      "72/72 [==============================] - 4s 57ms/step - loss: 1.5252 - accuracy: 0.4587 - val_loss: 1.8299 - val_accuracy: 0.3426\n"
     ]
    }
   ],
   "source": [
    "cnnhistory=model.fit(x_traincnn, \n",
    "                     y_train, \n",
    "                     batch_size=16, \n",
    "                     epochs=700, \n",
    "                     callbacks = [callback],\n",
    "                     validation_data=(x_testcnn, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cnnhistory.history['loss'])\n",
    "plt.plot(cnnhistory.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved trained model at C:\\Users\\colot\\OneDrive - Nanyang Technological University\\Backup\\Y3S1\\CZ4042 NNDL\\Speech-Emotion-Analyzer\\saved_models\\Emotion_Voice_Detection_Model.h5 \n"
     ]
    }
   ],
   "source": [
    "model_name = 'Emotion_Voice_Detection_Model.h5'\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "# Save model and weights\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "accuracy: 34.26%\n"
     ]
    }
   ],
   "source": [
    "# loading json and creating model\n",
    "from keras.models import model_from_json\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"saved_models/Emotion_Voice_Detection_Model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    " \n",
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "score = loaded_model.evaluate(x_testcnn, y_test, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting emotions on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = loaded_model.predict(x_testcnn, \n",
    "                         batch_size=32, \n",
    "                         verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds1=preds.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc = preds1.astype(int).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = (lb.inverse_transform((abc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preddf = pd.DataFrame({'predictedvalues': predictions})\n",
    "preddf[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual=y_test.argmax(axis=1)\n",
    "abc123 = actual.astype(int).flatten()\n",
    "actualvalues = (lb.inverse_transform((abc123)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actualdf = pd.DataFrame({'actualvalues': actualvalues})\n",
    "actualdf[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldf = actualdf.join(preddf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual v/s Predicted emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldf[170:180]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldf.groupby('actualvalues').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldf.groupby('predictedvalues').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldf.to_csv('Predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Live Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The file 'output10.wav' in the next cell is the file that was recorded live using the code in AudioRecoreder notebook found in the repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, sampling_rate = librosa.load('output10.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "% pylab inline\n",
    "import os\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import glob \n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "librosa.display.waveplot(data, sr=sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#livedf= pd.DataFrame(columns=['feature'])\n",
    "X, sample_rate = librosa.load('output10.wav', res_type='kaiser_fast',duration=2.5,sr=22050*2,offset=0.5)\n",
    "sample_rate = np.array(sample_rate)\n",
    "mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=13),axis=0)\n",
    "featurelive = mfccs\n",
    "livedf2 = featurelive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "livedf2= pd.DataFrame(data=livedf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "livedf2 = livedf2.stack().to_frame().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "livedf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twodim= np.expand_dims(livedf2, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "livepreds = loaded_model.predict(twodim, \n",
    "                         batch_size=32, \n",
    "                         verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "livepreds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "livepreds1=livepreds.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liveabc = livepreds1.astype(int).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "livepredictions = (lb.inverse_transform((liveabc)))\n",
    "livepredictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
